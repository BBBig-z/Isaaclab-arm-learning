--- git status ---
On branch main
Your branch is up to date with 'origin/main'.

Changes not staged for commit:
  (use "git add/rm <file>..." to update what will be committed)
  (use "git restore <file>..." to discard changes in working directory)
	modified:   .cursor/rules/example.mdc
	modified:   CONTRIBUTING.md
	modified:   CONTRIBUTORS.md
	modified:   README.md
	deleted:    scripts/list_envs.py
	deleted:    scripts/random_agent.py
	modified:   scripts/rsl_rl/play.py
	modified:   scripts/rsl_rl/train.py
	deleted:    scripts/skrl/play.py
	deleted:    scripts/skrl/train.py
	deleted:    scripts/zero_agent.py
	deleted:    source/SO_100/SO_100/__init__.py
	deleted:    source/SO_100/SO_100/robots/__init__.py
	deleted:    source/SO_100/SO_100/robots/so_arm100.py
	deleted:    source/SO_100/SO_100/robots/so_arm100_roscon.py
	deleted:    source/SO_100/SO_100/tasks/__init__.py
	deleted:    source/SO_100/SO_100/tasks/lift/__init__.py
	deleted:    source/SO_100/SO_100/tasks/lift/agents/__init__.py
	deleted:    source/SO_100/SO_100/tasks/lift/agents/rsl_rl_ppo_cfg.py
	deleted:    source/SO_100/SO_100/tasks/lift/joint_pos_env_cfg.py
	deleted:    source/SO_100/SO_100/tasks/lift/lift_env_cfg.py
	deleted:    source/SO_100/SO_100/tasks/lift/mdp/__init__.py
	deleted:    source/SO_100/SO_100/tasks/lift/mdp/observations.py
	deleted:    source/SO_100/SO_100/tasks/lift/mdp/rewards.py
	deleted:    source/SO_100/SO_100/tasks/lift/mdp/terminations.py
	deleted:    source/SO_100/SO_100/tasks/reach/__init__.py
	deleted:    source/SO_100/SO_100/tasks/reach/agents/__init__.py
	deleted:    source/SO_100/SO_100/tasks/reach/agents/rsl_rl_ppo_cfg.py
	deleted:    source/SO_100/SO_100/tasks/reach/agents/skrl_ppo_cfg.yaml
	deleted:    source/SO_100/SO_100/tasks/reach/ik_rel_env_cfg.py
	deleted:    source/SO_100/SO_100/tasks/reach/joint_pos_env_cfg.py
	deleted:    source/SO_100/SO_100/tasks/reach/mdp/__init__.py
	deleted:    source/SO_100/SO_100/tasks/reach/mdp/observations.py
	deleted:    source/SO_100/SO_100/tasks/reach/mdp/rewards.py
	deleted:    source/SO_100/SO_100/tasks/reach/mdp/terminations.py
	deleted:    source/SO_100/SO_100/tasks/reach/reach_env_cfg.py
	deleted:    source/SO_100/SO_100/ui_extension_example.py
	deleted:    source/SO_100/config/extension.toml
	deleted:    source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_base.usd
	deleted:    source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_physics.usd
	deleted:    source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_sensor.usd
	deleted:    source/SO_100/data/Robots/so_arm100/configuration/base_plate_layer1-v5.tmp.usd
	deleted:    source/SO_100/data/Robots/so_arm100/so_100.usd
	deleted:    source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_base.usd
	deleted:    source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_physics.usd
	deleted:    source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_sensor.usd
	deleted:    source/SO_100/data/Robots/so_arm100_roscon/so_arm100.usd
	deleted:    source/SO_100/docs/CHANGELOG.rst
	deleted:    source/SO_100/pyproject.toml
	deleted:    source/SO_100/setup.py

Untracked files:
  (use "git add <file>..." to include in what will be committed)
	"ARM_T_\350\256\255\347\273\203\346\214\207\345\215\227.md"
	analyze_pose_database.py
	generate_reachable_poses.py
	scripts/list_arm_t_envs.py
	scripts/rsl_rl/train_wandb_lift.py
	scripts/rsl_rl/train_wandb_reach.py
	scripts/rsl_rl/train_wandb_reach_ik.py
	source/ARM/
	train_arm_t.sh
	train_arm_t_wandb.sh

no changes added to commit (use "git add" and/or "git commit -a") 


--- git diff ---
diff --git a/.cursor/rules/example.mdc b/.cursor/rules/example.mdc
index 7e25479..d3b5285 100644
--- a/.cursor/rules/example.mdc
+++ b/.cursor/rules/example.mdc
@@ -1,6 +1,6 @@
 ---
-description:
-globs:
+description: ÊàëÈúÄË¶ÅËøÅÁßªËá™Â∑±ÁöÑÊ®°ÂûãÂà∞ËØ•È°πÁõÆ‰∏≠,ÊàëÁöÑÈ°πÁõÆËøêË°åÁéØÂ¢ÉÂú®conda‰∏≠ÁöÑ(isaaclab_env)
+globs: Áî®‰∏≠ÊñáÂõûÁ≠îÈóÆÈ¢ò
 alwaysApply: true
 ---
 
diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
index 8aaa670..69529f8 100644
--- a/CONTRIBUTING.md
+++ b/CONTRIBUTING.md
@@ -51,8 +51,8 @@ To push changes via SSH, you need to add your SSH key to your GitHub account.
 Follow the official guide here: **[GitHub SSH setup](https://docs.github.com/en/authentication/connecting-to-github-with-ssh)**
 
 ```bash
-git clone git@github.com:<your-username>/IsaacLab-SO_100.git
-cd IsaacLab-SO_100
+git clone git@github.com:<your-username>/IsaacLab-ARM.git
+cd IsaacLab-ARM
 ```
 
 Enable pre-commit hooks
@@ -67,7 +67,7 @@ pre-commit install
 To keep your fork up-to-date with the original project:
 
 ```bash
-git remote add upstream https://github.com/MuammerBay/IsaacLab-SO_100.git
+git remote add upstream https://github.com/MuammerBay/IsaacLab-ARM.git
 ```
 
 To fetch and merge changes from upstream later:
@@ -129,7 +129,7 @@ git push origin your-working-branch
 
 1. Go to your fork on GitHub.
 2. Click **Compare & pull request**.
-3. Set the **base repository** to `MuammerBay/IsaacLab-SO_100` and base branch to `main`.
+3. Set the **base repository** to `MuammerBay/IsaacLab-ARM` and base branch to `main`.
 4. Add a clear title and short description.
 5. Submit the pull request!
 
diff --git a/CONTRIBUTORS.md b/CONTRIBUTORS.md
index ac06f98..a267181 100644
--- a/CONTRIBUTORS.md
+++ b/CONTRIBUTORS.md
@@ -1,6 +1,6 @@
-# LycheeAI IsaacLab-SO_100 Developers and Contributors
+# LycheeAI IsaacLab-ARM Developers and Contributors
 
-This is the official list of LycheeAI IsaacLab-SO_100 project developers and contributors.
+This is the official list of LycheeAI IsaacLab-ARM project developers and contributors.
 
 To see the full list of contributors, please check the revision history in the source control.
 
diff --git a/README.md b/README.md
index 498f771..804dabd 100644
--- a/README.md
+++ b/README.md
@@ -33,7 +33,7 @@ There are official vendors who sell all the required parts and already assembled
 3. Install the package:
 
    ```bash
-   python -m pip install -e source/SO_100
+   python -m pip install -e source/ARM
    ```
 
 ## üöÄ Quickstart
diff --git a/scripts/list_envs.py b/scripts/list_envs.py
deleted file mode 100644
index 2b8effc..0000000
--- a/scripts/list_envs.py
+++ /dev/null
@@ -1,68 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""
-Script to print all the available environments in Isaac Lab.
-
-The script iterates over all registered environments and stores the details in a table.
-It prints the name of the environment, the entry point and the config file.
-
-All the environments are registered in the `SO_100` extension. They start
-with `Isaac` in their name.
-"""
-
-"""Launch Isaac Sim Simulator first."""
-
-from isaaclab.app import AppLauncher
-
-# launch omniverse app
-app_launcher = AppLauncher(headless=True)
-simulation_app = app_launcher.app
-
-
-"""Rest everything follows."""
-
-import gymnasium as gym
-import SO_100.tasks  # noqa: F401
-from prettytable import PrettyTable
-
-
-def main():
-    """Print all environments registered in `SO_100` extension."""
-    # print all the available environments
-    table = PrettyTable(["S. No.", "Task Name", "Entry Point", "Config"])
-    table.title = "Available Environments in Isaac Lab"
-    # set alignment of table columns
-    table.align["Task Name"] = "l"
-    table.align["Entry Point"] = "l"
-    table.align["Config"] = "l"
-
-    # count of environments
-    index = 0
-    # acquire all Isaac environments names
-    for task_spec in gym.registry.values():
-        if "SO-ARM100-" in task_spec.id:
-            # add details to table
-            table.add_row([index + 1, task_spec.id, task_spec.entry_point, task_spec.kwargs["env_cfg_entry_point"]])
-            # increment count
-            index += 1
-
-    print(table)
-
-
-if __name__ == "__main__":
-    try:
-        # run the main function
-        main()
-    except Exception as e:
-        raise e
-    finally:
-        # close the app
-        simulation_app.close()
diff --git a/scripts/random_agent.py b/scripts/random_agent.py
deleted file mode 100644
index 36da1da..0000000
--- a/scripts/random_agent.py
+++ /dev/null
@@ -1,75 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Script to an environment with random action agent."""
-
-"""Launch Isaac Sim Simulator first."""
-
-import argparse
-
-from isaaclab.app import AppLauncher
-
-# add argparse arguments
-parser = argparse.ArgumentParser(description="Random agent for Isaac Lab environments.")
-parser.add_argument(
-    "--disable_fabric", action="store_true", default=False, help="Disable fabric and use USD I/O operations."
-)
-parser.add_argument("--num_envs", type=int, default=None, help="Number of environments to simulate.")
-parser.add_argument("--task", type=str, default=None, help="Name of the task.")
-# append AppLauncher cli args
-AppLauncher.add_app_launcher_args(parser)
-# parse the arguments
-args_cli = parser.parse_args()
-
-# launch omniverse app
-app_launcher = AppLauncher(args_cli)
-simulation_app = app_launcher.app
-
-"""Rest everything follows."""
-
-import gymnasium as gym
-import isaaclab_tasks  # noqa: F401
-import SO_100.tasks  # noqa: F401
-import torch
-from isaaclab_tasks.utils import parse_env_cfg
-
-
-def main():
-    """Random actions agent with Isaac Lab environment."""
-    # create environment configuration
-    env_cfg = parse_env_cfg(
-        args_cli.task, device=args_cli.device, num_envs=args_cli.num_envs, use_fabric=not args_cli.disable_fabric
-    )
-    # create environment
-    env = gym.make(args_cli.task, cfg=env_cfg)
-
-    # print info (this is vectorized environment)
-    print(f"[INFO]: Gym observation space: {env.observation_space}")
-    print(f"[INFO]: Gym action space: {env.action_space}")
-    # reset environment
-    env.reset()
-    # simulate environment
-    while simulation_app.is_running():
-        # run everything in inference mode
-        with torch.inference_mode():
-            # sample actions from -1 to 1
-            actions = 2 * torch.rand(env.action_space.shape, device=env.unwrapped.device) - 1
-            # apply actions
-            env.step(actions)
-
-    # close the simulator
-    env.close()
-
-
-if __name__ == "__main__":
-    # run the main function
-    main()
-    # close sim app
-    simulation_app.close()
diff --git a/scripts/rsl_rl/play.py b/scripts/rsl_rl/play.py
index a9a98e5..66ecd09 100644
--- a/scripts/rsl_rl/play.py
+++ b/scripts/rsl_rl/play.py
@@ -59,11 +59,19 @@ simulation_app = app_launcher.app
 """Rest everything follows."""
 
 import os
+import sys
 import time
 
+# Ê∑ªÂä† arm_t Ê®°ÂùóË∑ØÂæÑÂà∞ sys.path
+workspace_path = os.path.abspath(os.path.join(os.path.dirname(__file__), "../.."))
+arm_t_path = os.path.join(workspace_path, "source/ARM")
+if arm_t_path not in sys.path:
+    sys.path.insert(0, arm_t_path)
+    print(f"[INFO] Â∑≤Ê∑ªÂä†Ë∑ØÂæÑÂà∞ sys.path: {arm_t_path}")
+
 import gymnasium as gym
 import isaaclab_tasks  # noqa: F401
-import SO_100.tasks  # noqa: F401
+import arm_t.tasks  # noqa: F401
 import torch
 from isaaclab.envs import (
     DirectMARLEnv,
@@ -76,25 +84,25 @@ from isaaclab.utils.assets import retrieve_file_path
 from isaaclab.utils.dict import print_dict
 from isaaclab.utils.pretrained_checkpoint import get_published_pretrained_checkpoint
 from isaaclab_rl.rsl_rl import (
-    RslRlBaseRunnerCfg,
+    RslRlOnPolicyRunnerCfg,
     RslRlVecEnvWrapper,
     export_policy_as_jit,
     export_policy_as_onnx,
 )
 from isaaclab_tasks.utils import get_checkpoint_path
 from isaaclab_tasks.utils.hydra import hydra_task_config
-from rsl_rl.runners import DistillationRunner, OnPolicyRunner
+from rsl_rl.runners import OnPolicyRunner
 
 
 @hydra_task_config(args_cli.task, args_cli.agent)
-def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agent_cfg: RslRlBaseRunnerCfg):
+def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agent_cfg: RslRlOnPolicyRunnerCfg):
     """Play with RSL-RL agent."""
     # grab task name for checkpoint path
     task_name = args_cli.task.split(":")[-1]
     train_task_name = task_name.replace("-Play", "")
 
     # override configurations with non-hydra CLI arguments
-    agent_cfg: RslRlBaseRunnerCfg = cli_args.update_rsl_rl_cfg(agent_cfg, args_cli)
+    agent_cfg: RslRlOnPolicyRunnerCfg = cli_args.update_rsl_rl_cfg(agent_cfg, args_cli)
     env_cfg.scene.num_envs = args_cli.num_envs if args_cli.num_envs is not None else env_cfg.scene.num_envs
 
     # set the environment seed
@@ -142,12 +150,7 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
 
     print(f"[INFO]: Loading model checkpoint from: {resume_path}")
     # load previously trained model
-    if agent_cfg.class_name == "OnPolicyRunner":
-        runner = OnPolicyRunner(env, agent_cfg.to_dict(), log_dir=None, device=agent_cfg.device)
-    elif agent_cfg.class_name == "DistillationRunner":
-        runner = DistillationRunner(env, agent_cfg.to_dict(), log_dir=None, device=agent_cfg.device)
-    else:
-        raise ValueError(f"Unsupported runner class: {agent_cfg.class_name}")
+    runner = OnPolicyRunner(env, agent_cfg.to_dict(), log_dir=None, device=agent_cfg.device)
     runner.load(resume_path)
 
     # obtain the trained policy for inference
@@ -178,7 +181,7 @@ def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agen
     dt = env.unwrapped.step_dt
 
     # reset environment
-    obs = env.get_observations()
+    obs, _ = env.get_observations()
     timestep = 0
     # simulate environment
     while simulation_app.is_running():
diff --git a/scripts/rsl_rl/train.py b/scripts/rsl_rl/train.py
index e68f512..87b8aaa 100644
--- a/scripts/rsl_rl/train.py
+++ b/scripts/rsl_rl/train.py
@@ -79,7 +79,7 @@ from datetime import datetime
 
 import gymnasium as gym
 import isaaclab_tasks  # noqa: F401
-import SO_100.tasks  # noqa: F401
+import arm_t.tasks  # noqa: F401
 import torch
 from isaaclab.envs import (
     DirectMARLEnv,
diff --git a/scripts/skrl/play.py b/scripts/skrl/play.py
deleted file mode 100644
index 42d334d..0000000
--- a/scripts/skrl/play.py
+++ /dev/null
@@ -1,217 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""
-Script to play a checkpoint of an RL agent from skrl.
-
-Visit the skrl documentation (https://skrl.readthedocs.io) to see the examples structured in
-a more user-friendly way.
-"""
-
-"""Launch Isaac Sim Simulator first."""
-
-import argparse
-
-from isaaclab.app import AppLauncher
-
-# add argparse arguments
-parser = argparse.ArgumentParser(description="Play a checkpoint of an RL agent from skrl.")
-parser.add_argument("--video", action="store_true", default=False, help="Record videos during training.")
-parser.add_argument("--video_length", type=int, default=200, help="Length of the recorded video (in steps).")
-parser.add_argument(
-    "--disable_fabric", action="store_true", default=False, help="Disable fabric and use USD I/O operations."
-)
-parser.add_argument("--num_envs", type=int, default=None, help="Number of environments to simulate.")
-parser.add_argument("--task", type=str, default=None, help="Name of the task.")
-parser.add_argument("--checkpoint", type=str, default=None, help="Path to model checkpoint.")
-parser.add_argument(
-    "--use_pretrained_checkpoint",
-    action="store_true",
-    help="Use the pre-trained checkpoint from Nucleus.",
-)
-parser.add_argument(
-    "--ml_framework",
-    type=str,
-    default="torch",
-    choices=["torch", "jax", "jax-numpy"],
-    help="The ML framework used for training the skrl agent.",
-)
-parser.add_argument(
-    "--algorithm",
-    type=str,
-    default="PPO",
-    choices=["AMP", "PPO", "IPPO", "MAPPO"],
-    help="The RL algorithm used for training the skrl agent.",
-)
-parser.add_argument("--real-time", action="store_true", default=False, help="Run in real-time, if possible.")
-
-# append AppLauncher cli args
-AppLauncher.add_app_launcher_args(parser)
-args_cli = parser.parse_args()
-# always enable cameras to record video
-if args_cli.video:
-    args_cli.enable_cameras = True
-
-# launch omniverse app
-app_launcher = AppLauncher(args_cli)
-simulation_app = app_launcher.app
-
-"""Rest everything follows."""
-
-import os
-import time
-
-import gymnasium as gym
-import skrl
-import torch
-from packaging import version
-
-# check for minimum supported skrl version
-SKRL_VERSION = "1.4.2"
-if version.parse(skrl.__version__) < version.parse(SKRL_VERSION):
-    skrl.logger.error(
-        f"Unsupported skrl version: {skrl.__version__}. "
-        f"Install supported version using 'pip install skrl>={SKRL_VERSION}'"
-    )
-    exit()
-
-if args_cli.ml_framework.startswith("torch"):
-    from skrl.utils.runner.torch import Runner
-elif args_cli.ml_framework.startswith("jax"):
-    from skrl.utils.runner.jax import Runner
-
-import isaaclab_tasks  # noqa: F401
-import SO_100.tasks  # noqa: F401
-from isaaclab.envs import DirectMARLEnv, multi_agent_to_single_agent
-from isaaclab.utils.dict import print_dict
-from isaaclab.utils.pretrained_checkpoint import get_published_pretrained_checkpoint
-from isaaclab_rl.skrl import SkrlVecEnvWrapper
-from isaaclab_tasks.utils import (
-    get_checkpoint_path,
-    load_cfg_from_registry,
-    parse_env_cfg,
-)
-
-# config shortcuts
-algorithm = args_cli.algorithm.lower()
-
-
-def main():
-    """Play with skrl agent."""
-    # configure the ML framework into the global skrl variable
-    if args_cli.ml_framework.startswith("jax"):
-        skrl.config.jax.backend = "jax" if args_cli.ml_framework == "jax" else "numpy"
-
-    # parse configuration
-    env_cfg = parse_env_cfg(
-        args_cli.task, device=args_cli.device, num_envs=args_cli.num_envs, use_fabric=not args_cli.disable_fabric
-    )
-    try:
-        experiment_cfg = load_cfg_from_registry(args_cli.task, f"skrl_{algorithm}_cfg_entry_point")
-    except ValueError:
-        experiment_cfg = load_cfg_from_registry(args_cli.task, "skrl_cfg_entry_point")
-
-    # specify directory for logging experiments (load checkpoint)
-    log_root_path = os.path.join("logs", "skrl", experiment_cfg["agent"]["experiment"]["directory"])
-    log_root_path = os.path.abspath(log_root_path)
-    print(f"[INFO] Loading experiment from directory: {log_root_path}")
-    # get checkpoint path
-    if args_cli.use_pretrained_checkpoint:
-        resume_path = get_published_pretrained_checkpoint("skrl", args_cli.task)
-        if not resume_path:
-            print("[INFO] Unfortunately a pre-trained checkpoint is currently unavailable for this task.")
-            return
-    elif args_cli.checkpoint:
-        resume_path = os.path.abspath(args_cli.checkpoint)
-    else:
-        resume_path = get_checkpoint_path(
-            log_root_path, run_dir=f".*_{algorithm}_{args_cli.ml_framework}", other_dirs=["checkpoints"]
-        )
-    log_dir = os.path.dirname(os.path.dirname(resume_path))
-
-    # create isaac environment
-    env = gym.make(args_cli.task, cfg=env_cfg, render_mode="rgb_array" if args_cli.video else None)
-
-    # convert to single-agent instance if required by the RL algorithm
-    if isinstance(env.unwrapped, DirectMARLEnv) and algorithm in ["ppo"]:
-        env = multi_agent_to_single_agent(env)
-
-    # get environment (step) dt for real-time evaluation
-    try:
-        dt = env.step_dt
-    except AttributeError:
-        dt = env.unwrapped.step_dt
-
-    # wrap for video recording
-    if args_cli.video:
-        video_kwargs = {
-            "video_folder": os.path.join(log_dir, "videos", "play"),
-            "step_trigger": lambda step: step == 0,
-            "video_length": args_cli.video_length,
-            "disable_logger": True,
-        }
-        print("[INFO] Recording videos during training.")
-        print_dict(video_kwargs, nesting=4)
-        env = gym.wrappers.RecordVideo(env, **video_kwargs)
-
-    # wrap around environment for skrl
-    env = SkrlVecEnvWrapper(env, ml_framework=args_cli.ml_framework)  # same as: `wrap_env(env, wrapper="auto")`
-
-    # configure and instantiate the skrl runner
-    # https://skrl.readthedocs.io/en/latest/api/utils/runner.html
-    experiment_cfg["trainer"]["close_environment_at_exit"] = False
-    experiment_cfg["agent"]["experiment"]["write_interval"] = 0  # don't log to TensorBoard
-    experiment_cfg["agent"]["experiment"]["checkpoint_interval"] = 0  # don't generate checkpoints
-    runner = Runner(env, experiment_cfg)
-
-    print(f"[INFO] Loading model checkpoint from: {resume_path}")
-    runner.agent.load(resume_path)
-    # set agent to evaluation mode
-    runner.agent.set_running_mode("eval")
-
-    # reset environment
-    obs, _ = env.reset()
-    timestep = 0
-    # simulate environment
-    while simulation_app.is_running():
-        start_time = time.time()
-
-        # run everything in inference mode
-        with torch.inference_mode():
-            # agent stepping
-            outputs = runner.agent.act(obs, timestep=0, timesteps=0)
-            # - multi-agent (deterministic) actions
-            if hasattr(env, "possible_agents"):
-                actions = {a: outputs[-1][a].get("mean_actions", outputs[0][a]) for a in env.possible_agents}
-            # - single-agent (deterministic) actions
-            else:
-                actions = outputs[-1].get("mean_actions", outputs[0])
-            # env stepping
-            obs, _, _, _, _ = env.step(actions)
-        if args_cli.video:
-            timestep += 1
-            # exit the play loop after recording one video
-            if timestep == args_cli.video_length:
-                break
-
-        # time delay for real-time evaluation
-        sleep_time = dt - (time.time() - start_time)
-        if args_cli.real_time and sleep_time > 0:
-            time.sleep(sleep_time)
-
-    # close the simulator
-    env.close()
-
-
-if __name__ == "__main__":
-    # run the main function
-    main()
-    # close sim app
-    simulation_app.close()
diff --git a/scripts/skrl/train.py b/scripts/skrl/train.py
deleted file mode 100644
index 2c097e9..0000000
--- a/scripts/skrl/train.py
+++ /dev/null
@@ -1,198 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-import argparse
-import sys
-
-from isaaclab.app import AppLauncher
-
-# add argparse arguments
-parser = argparse.ArgumentParser(description="Train an RL agent with skrl.")
-parser.add_argument("--video", action="store_true", default=False, help="Record videos during training.")
-parser.add_argument("--video_length", type=int, default=200, help="Length of the recorded video (in steps).")
-parser.add_argument("--video_interval", type=int, default=2000, help="Interval between video recordings (in steps).")
-parser.add_argument("--num_envs", type=int, default=None, help="Number of environments to simulate.")
-parser.add_argument("--task", type=str, default=None, help="Name of the task.")
-parser.add_argument("--seed", type=int, default=None, help="Seed used for the environment")
-parser.add_argument(
-    "--distributed", action="store_true", default=False, help="Run training with multiple GPUs or nodes."
-)
-parser.add_argument("--checkpoint", type=str, default=None, help="Path to model checkpoint to resume training.")
-parser.add_argument("--max_iterations", type=int, default=None, help="RL Policy training iterations.")
-parser.add_argument(
-    "--ml_framework",
-    type=str,
-    default="torch",
-    choices=["torch", "jax", "jax-numpy"],
-    help="The ML framework used for training the skrl agent.",
-)
-parser.add_argument(
-    "--algorithm",
-    type=str,
-    default="PPO",
-    choices=["AMP", "PPO", "IPPO", "MAPPO"],
-    help="The RL algorithm used for training the skrl agent.",
-)
-
-# append AppLauncher cli args
-AppLauncher.add_app_launcher_args(parser)
-# parse the arguments
-args_cli, hydra_args = parser.parse_known_args()
-# always enable cameras to record video
-if args_cli.video:
-    args_cli.enable_cameras = True
-
-# clear out sys.argv for Hydra
-sys.argv = [sys.argv[0]] + hydra_args
-
-# launch omniverse app
-app_launcher = AppLauncher(args_cli)
-simulation_app = app_launcher.app
-
-"""Rest everything follows."""
-
-import os
-import random
-from datetime import datetime
-
-import gymnasium as gym
-import skrl
-from packaging import version
-
-# check for minimum supported skrl version
-SKRL_VERSION = "1.4.2"
-if version.parse(skrl.__version__) < version.parse(SKRL_VERSION):
-    skrl.logger.error(
-        f"Unsupported skrl version: {skrl.__version__}. "
-        f"Install supported version using 'pip install skrl>={SKRL_VERSION}'"
-    )
-    exit()
-
-if args_cli.ml_framework.startswith("torch"):
-    from skrl.utils.runner.torch import Runner
-elif args_cli.ml_framework.startswith("jax"):
-    from skrl.utils.runner.jax import Runner
-
-import isaaclab_tasks  # noqa: F401
-import SO_100.tasks  # noqa: F401
-from isaaclab.envs import (
-    DirectMARLEnv,
-    DirectMARLEnvCfg,
-    DirectRLEnvCfg,
-    ManagerBasedRLEnvCfg,
-    multi_agent_to_single_agent,
-)
-from isaaclab.utils.assets import retrieve_file_path
-from isaaclab.utils.dict import print_dict
-from isaaclab.utils.io import dump_pickle, dump_yaml
-from isaaclab_rl.skrl import SkrlVecEnvWrapper
-from isaaclab_tasks.utils.hydra import hydra_task_config
-
-# config shortcuts
-algorithm = args_cli.algorithm.lower()
-agent_cfg_entry_point = "skrl_cfg_entry_point" if algorithm in ["ppo"] else f"skrl_{algorithm}_cfg_entry_point"
-
-gym.pprint_registry()
-
-
-@hydra_task_config(args_cli.task, agent_cfg_entry_point)
-def main(env_cfg: ManagerBasedRLEnvCfg | DirectRLEnvCfg | DirectMARLEnvCfg, agent_cfg: dict):
-    """Train with skrl agent."""
-    # override configurations with non-hydra CLI arguments
-    env_cfg.scene.num_envs = args_cli.num_envs if args_cli.num_envs is not None else env_cfg.scene.num_envs
-    env_cfg.sim.device = args_cli.device if args_cli.device is not None else env_cfg.sim.device
-
-    # multi-gpu training config
-    if args_cli.distributed:
-        env_cfg.sim.device = f"cuda:{app_launcher.local_rank}"
-    # max iterations for training
-    if args_cli.max_iterations:
-        agent_cfg["trainer"]["timesteps"] = args_cli.max_iterations * agent_cfg["agent"]["rollouts"]
-    agent_cfg["trainer"]["close_environment_at_exit"] = False
-    # configure the ML framework into the global skrl variable
-    if args_cli.ml_framework.startswith("jax"):
-        skrl.config.jax.backend = "jax" if args_cli.ml_framework == "jax" else "numpy"
-
-    # randomly sample a seed if seed = -1
-    if args_cli.seed == -1:
-        args_cli.seed = random.randint(0, 10000)
-
-    # set the agent and environment seed from command line
-    # note: certain randomization occur in the environment initialization so we set the seed here
-    agent_cfg["seed"] = args_cli.seed if args_cli.seed is not None else agent_cfg["seed"]
-    env_cfg.seed = agent_cfg["seed"]
-
-    # specify directory for logging experiments
-    log_root_path = os.path.join("logs", "skrl", agent_cfg["agent"]["experiment"]["directory"])
-    log_root_path = os.path.abspath(log_root_path)
-    print(f"[INFO] Logging experiment in directory: {log_root_path}")
-    # specify directory for logging runs: {time-stamp}_{run_name}
-    log_dir = datetime.now().strftime("%Y-%m-%d_%H-%M-%S") + f"_{algorithm}_{args_cli.ml_framework}"
-    print(f"Exact experiment name requested from command line {log_dir}")
-    if agent_cfg["agent"]["experiment"]["experiment_name"]:
-        log_dir += f'_{agent_cfg["agent"]["experiment"]["experiment_name"]}'
-    # set directory into agent config
-    agent_cfg["agent"]["experiment"]["directory"] = log_root_path
-    agent_cfg["agent"]["experiment"]["experiment_name"] = log_dir
-    # update log_dir
-    log_dir = os.path.join(log_root_path, log_dir)
-
-    # dump the configuration into log-directory
-    dump_yaml(os.path.join(log_dir, "params", "env.yaml"), env_cfg)
-    dump_yaml(os.path.join(log_dir, "params", "agent.yaml"), agent_cfg)
-    dump_pickle(os.path.join(log_dir, "params", "env.pkl"), env_cfg)
-    dump_pickle(os.path.join(log_dir, "params", "agent.pkl"), agent_cfg)
-
-    # get checkpoint path (to resume training)
-    resume_path = retrieve_file_path(args_cli.checkpoint) if args_cli.checkpoint else None
-
-    # create isaac environment
-    env = gym.make(args_cli.task, cfg=env_cfg, render_mode="rgb_array" if args_cli.video else None)
-
-    # wrap for video recording
-    if args_cli.video:
-        video_kwargs = {
-            "video_folder": os.path.join(log_dir, "videos", "train"),
-            "step_trigger": lambda step: step % args_cli.video_interval == 0,
-            "video_length": args_cli.video_length,
-            "disable_logger": True,
-        }
-        print("[INFO] Recording videos during training.")
-        print_dict(video_kwargs, nesting=4)
-        env = gym.wrappers.RecordVideo(env, **video_kwargs)
-
-    # convert to single-agent instance if required by the RL algorithm
-    if isinstance(env.unwrapped, DirectMARLEnv) and algorithm in ["ppo"]:
-        env = multi_agent_to_single_agent(env)
-
-    # wrap around environment for skrl
-    env = SkrlVecEnvWrapper(env, ml_framework=args_cli.ml_framework)  # same as: `wrap_env(env, wrapper="auto")`
-
-    # configure and instantiate the skrl runner
-    # https://skrl.readthedocs.io/en/latest/api/utils/runner.html
-    runner = Runner(env, agent_cfg)
-
-    # load checkpoint (if specified)
-    if resume_path:
-        print(f"[INFO] Loading model checkpoint from: {resume_path}")
-        runner.agent.load(resume_path)
-
-    # run training
-    runner.run()
-
-    # close the simulator
-    env.close()
-
-
-if __name__ == "__main__":
-    # run the main function
-    main()
-    # close sim app
-    simulation_app.close()
diff --git a/scripts/zero_agent.py b/scripts/zero_agent.py
deleted file mode 100644
index 2d15067..0000000
--- a/scripts/zero_agent.py
+++ /dev/null
@@ -1,75 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Script to run an environment with zero action agent."""
-
-"""Launch Isaac Sim Simulator first."""
-
-import argparse
-
-from isaaclab.app import AppLauncher
-
-# add argparse arguments
-parser = argparse.ArgumentParser(description="Zero agent for Isaac Lab environments.")
-parser.add_argument(
-    "--disable_fabric", action="store_true", default=False, help="Disable fabric and use USD I/O operations."
-)
-parser.add_argument("--num_envs", type=int, default=None, help="Number of environments to simulate.")
-parser.add_argument("--task", type=str, default=None, help="Name of the task.")
-# append AppLauncher cli args
-AppLauncher.add_app_launcher_args(parser)
-# parse the arguments
-args_cli = parser.parse_args()
-
-# launch omniverse app
-app_launcher = AppLauncher(args_cli)
-simulation_app = app_launcher.app
-
-"""Rest everything follows."""
-
-import gymnasium as gym
-import isaaclab_tasks  # noqa: F401
-import SO_100.tasks  # noqa: F401
-import torch
-from isaaclab_tasks.utils import parse_env_cfg
-
-
-def main():
-    """Zero actions agent with Isaac Lab environment."""
-    # parse configuration
-    env_cfg = parse_env_cfg(
-        args_cli.task, device=args_cli.device, num_envs=args_cli.num_envs, use_fabric=not args_cli.disable_fabric
-    )
-    # create environment
-    env = gym.make(args_cli.task, cfg=env_cfg)
-
-    # print info (this is vectorized environment)
-    print(f"[INFO]: Gym observation space: {env.observation_space}")
-    print(f"[INFO]: Gym action space: {env.action_space}")
-    # reset environment
-    env.reset()
-    # simulate environment
-    while simulation_app.is_running():
-        # run everything in inference mode
-        with torch.inference_mode():
-            # compute zero actions
-            actions = torch.zeros(env.action_space.shape, device=env.unwrapped.device)
-            # apply actions
-            env.step(actions)
-
-    # close the simulator
-    env.close()
-
-
-if __name__ == "__main__":
-    # run the main function
-    main()
-    # close sim app
-    simulation_app.close()
diff --git a/source/SO_100/SO_100/__init__.py b/source/SO_100/SO_100/__init__.py
deleted file mode 100644
index 66e4dd9..0000000
--- a/source/SO_100/SO_100/__init__.py
+++ /dev/null
@@ -1,19 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""
-Python module serving as a project/extension template.
-"""
-
-# Register Gym environments.
-from .tasks import *
-
-# Register UI extensions.
-from .ui_extension_example import *
diff --git a/source/SO_100/SO_100/robots/__init__.py b/source/SO_100/SO_100/robots/__init__.py
deleted file mode 100644
index aa0a926..0000000
--- a/source/SO_100/SO_100/robots/__init__.py
+++ /dev/null
@@ -1,12 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from .so_arm100 import *
-from .so_arm100_roscon import *
diff --git a/source/SO_100/SO_100/robots/so_arm100.py b/source/SO_100/SO_100/robots/so_arm100.py
deleted file mode 100644
index 058b26e..0000000
--- a/source/SO_100/SO_100/robots/so_arm100.py
+++ /dev/null
@@ -1,96 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Configuration for the SO-ARM100 5-DOF robot arm for livestream.
-
-The following configurations are available:
-
-* :obj:`SO_ARM100_CFG`: SO-ARM100 robot arm configuration.
-"""
-
-from pathlib import Path
-
-import isaaclab.sim as sim_utils
-from isaaclab.actuators import ImplicitActuatorCfg
-from isaaclab.assets.articulation import ArticulationCfg
-
-TEMPLATE_ASSETS_DATA_DIR = Path(__file__).resolve().parent.parent.parent / "data"
-
-##
-# Configuration
-##
-
-
-SO_ARM100_CFG = ArticulationCfg(
-    spawn=sim_utils.UsdFileCfg(
-        usd_path=f"{TEMPLATE_ASSETS_DATA_DIR}/Robots/so_arm100/so_100.usd",
-        activate_contact_sensors=False,  # Adjust based on need
-        rigid_props=sim_utils.RigidBodyPropertiesCfg(
-            disable_gravity=False,
-            max_depenetration_velocity=5.0,
-        ),
-        articulation_props=sim_utils.ArticulationRootPropertiesCfg(
-            enabled_self_collisions=True,
-            solver_position_iteration_count=8,
-            solver_velocity_iteration_count=0,
-        ),
-    ),
-    init_state=ArticulationCfg.InitialStateCfg(
-        rot=(0.7071068, 0.0, 0.0, 0.7071068),  # Quaternion for 90 degrees rotation around Y-axis
-        joint_pos={
-            "Shoulder_Rotation": 0.0,
-            "Shoulder_Pitch": 0.0,
-            "Elbow": 0.0,
-            "Wrist_Pitch": 0.0,
-            "Wrist_Roll": 0.0,
-            "Gripper": 0.3,  # Middle position to make movement more apparent
-        },
-        # Set initial joint velocities to zero
-        joint_vel={".*": 0.0},
-    ),
-    actuators={
-        # Shoulder Pan      moves: ALL masses                   (~0.8kg total)
-        # Shoulder Lift     moves: Everything except base       (~0.65kg)
-        # Elbow             moves: Lower arm, wrist, gripper    (~0.38kg)
-        # Wrist Pitch       moves: Wrist and gripper            (~0.24kg)
-        # Wrist Roll        moves: Gripper assembly             (~0.14kg)
-        # Jaw               moves: Only moving jaw              (~0.034kg)
-        "arm": ImplicitActuatorCfg(
-            joint_names_expr=["Shoulder_.*", "Elbow", "Wrist_.*"],
-            effort_limit_sim=1.9,
-            velocity_limit_sim=1.5,
-            stiffness={
-                "Shoulder_Rotation": 200.0,  # Highest - moves all mass
-                "Shoulder_Pitch": 170.0,  # Slightly less than rotation
-                "Elbow": 120.0,  # Reduced based on less mass
-                "Wrist_Pitch": 80.0,  # Reduced for less mass
-                "Wrist_Roll": 50.0,  # Low mass to move
-            },
-            damping={
-                "Shoulder_Rotation": 80.0,
-                "Shoulder_Pitch": 65.0,
-                "Elbow": 45.0,
-                "Wrist_Pitch": 30.0,
-                "Wrist_Roll": 20.0,
-            },
-        ),
-        "gripper": ImplicitActuatorCfg(
-            joint_names_expr=["Gripper"],
-            effort_limit_sim=2.5,  # Increased from 1.9 to 2.5 for stronger grip
-            velocity_limit_sim=1.5,
-            stiffness=60.0,  # Increased from 25.0 to 60.0 for more reliable closing
-            damping=20.0,  # Increased from 10.0 to 20.0 for stability
-        ),
-    },
-    soft_joint_pos_limit_factor=1.0,
-)
-"""Configuration of SO-ARM robot arm."""
-
-# Removed FRANKA_PANDA_HIGH_PD_CFG as it's not applicable here.
diff --git a/source/SO_100/SO_100/robots/so_arm100_roscon.py b/source/SO_100/SO_100/robots/so_arm100_roscon.py
deleted file mode 100644
index b6dcd96..0000000
--- a/source/SO_100/SO_100/robots/so_arm100_roscon.py
+++ /dev/null
@@ -1,120 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Configuration for the SO-ARM100 5-DOF robot arm for livestream.
-
-The following configurations are available:
-
-* :obj:`SO_ARM100_ROSCON_CFG`: SO-ARM100 robot arm configuration more adapted for sim2real.
-        ->  converted from the xacro of this repository:
-        https://github.com/JafarAbdi/ros2_so_arm100
-"""
-
-from pathlib import Path
-
-import isaaclab.sim as sim_utils
-from isaaclab.actuators import ImplicitActuatorCfg
-from isaaclab.assets.articulation import ArticulationCfg
-
-TEMPLATE_ASSETS_DATA_DIR = Path(__file__).resolve().parent.parent.parent / "data"
-
-##
-# Configuration
-##
-
-SO_ARM100_ROSCON_CFG = ArticulationCfg(
-    spawn=sim_utils.UsdFileCfg(
-        usd_path=f"{TEMPLATE_ASSETS_DATA_DIR}/Robots/so_arm100_roscon/so_arm100.usd",
-        activate_contact_sensors=False,  # Adjust based on need
-        rigid_props=sim_utils.RigidBodyPropertiesCfg(
-            disable_gravity=False,
-            max_depenetration_velocity=5.0,
-        ),
-        articulation_props=sim_utils.ArticulationRootPropertiesCfg(
-            enabled_self_collisions=True,
-            solver_position_iteration_count=8,
-            solver_velocity_iteration_count=0,
-        ),
-    ),
-    init_state=ArticulationCfg.InitialStateCfg(
-        rot=(0.7071068, 0.0, 0.0, 0.7071068),  # Quaternion for 90 degrees rotation around Y-axis
-        joint_pos={
-            "shoulder_pan_joint": 0.0,
-            "shoulder_lift_joint": 0.0,
-            "elbow_joint": 0.0,
-            "wrist_pitch_joint": 0.0,
-            "wrist_roll_joint": 0.0,
-            "jaw_joint": 0.1,  # Middle position to make movement more apparent
-        },
-        # Set initial joint velocities to zero
-        joint_vel={".*": 0.0},
-    ),
-    actuators={
-        # Shoulder Pan      moves: ALL masses                   (~0.8kg total)
-        # Shoulder Lift     moves: Everything except base       (~0.65kg)
-        # Elbow             moves: Lower arm, wrist, gripper    (~0.38kg)
-        # Wrist Pitch       moves: Wrist and gripper            (~0.24kg)
-        # Wrist Roll        moves: Gripper assembly             (~0.14kg)
-        # Jaw               moves: Only moving jaw              (~0.034kg)
-        "arm": ImplicitActuatorCfg(
-            joint_names_expr=["shoulder_.*", "elbow_joint", "wrist_.*"],
-            effort_limit_sim=1.9,
-            velocity_limit_sim=1.5,
-            stiffness={
-                "shoulder_pan_joint": 200.0,  # Highest - moves all mass
-                "shoulder_lift_joint": 170.0,  # Slightly less than rotation
-                "elbow_joint": 120.0,  # Reduced based on less mass
-                "wrist_pitch_joint": 80.0,  # Reduced for less mass
-                "wrist_roll_joint": 50.0,  # Low mass to move
-            },
-            damping={
-                "shoulder_pan_joint": 80.0,
-                "shoulder_lift_joint": 65.0,
-                "elbow_joint": 45.0,
-                "wrist_pitch_joint": 30.0,
-                "wrist_roll_joint": 20.0,
-            },
-        ),
-        "gripper": ImplicitActuatorCfg(
-            joint_names_expr=["jaw_joint"],
-            effort_limit_sim=2.5,  # Increased from 1.9 to 2.5 for stronger grip
-            velocity_limit_sim=1.5,
-            stiffness=60.0,  # Increased from 25.0 to 60.0 for more reliable closing
-            damping=20.0,  # Increased from 10.0 to 20.0 for stability
-        ),
-    },
-    soft_joint_pos_limit_factor=1.0,
-)
-
-"""Configuration of SO-ARM robot more adapted for sim2real."""
-
-SO_ARM100_ROSCON_HIGH_PD_CFG = SO_ARM100_ROSCON_CFG.copy()
-SO_ARM100_ROSCON_HIGH_PD_CFG.spawn.rigid_props.disable_gravity = True
-SO_ARM100_ROSCON_HIGH_PD_CFG.actuators["arm"].stiffness = {
-    "shoulder_pan_joint": 500.0,  # Highest - moves all mass
-    "shoulder_lift_joint": 500.0,  # Slightly less than rotation
-    "elbow_joint": 400.0,  # Reduced based on less mass
-    "wrist_pitch_joint": 300.0,  # Reduced for less mass
-    "wrist_roll_joint": 300.0,  # Low mass to move
-}
-SO_ARM100_ROSCON_HIGH_PD_CFG.actuators["arm"].damping = {
-    "shoulder_pan_joint": 150.0,
-    "shoulder_lift_joint": 150.0,
-    "elbow_joint": 120.0,
-    "wrist_pitch_joint": 90.0,
-    "wrist_roll_joint": 90.0,
-}
-
-"""Configuration of SO-ARM robot with stiffer PD control."""
diff --git a/source/SO_100/SO_100/tasks/__init__.py b/source/SO_100/SO_100/tasks/__init__.py
deleted file mode 100644
index 94384ab..0000000
--- a/source/SO_100/SO_100/tasks/__init__.py
+++ /dev/null
@@ -1,22 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Package containing task implementations for the extension."""
-
-##
-# Register Gym environments.
-##
-
-from isaaclab_tasks.utils import import_packages
-
-# The blacklist is used to prevent importing configs from sub-packages
-_BLACKLIST_PKGS = ["utils", ".mdp"]
-# Import all configs in this package
-import_packages(__name__, _BLACKLIST_PKGS)
diff --git a/source/SO_100/SO_100/tasks/lift/__init__.py b/source/SO_100/SO_100/tasks/lift/__init__.py
deleted file mode 100644
index 9301738..0000000
--- a/source/SO_100/SO_100/tasks/lift/__init__.py
+++ /dev/null
@@ -1,38 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-import gymnasium as gym
-
-from . import agents
-
-##
-# Register Gym environments.
-##
-
-# Register the SO-100 Cube Lift environment
-gym.register(
-    id="SO-ARM100-Lift-Cube-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.joint_pos_env_cfg:SoArm100CubeCubeLiftEnvCfg",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:LiftCubePPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
-
-gym.register(
-    id="SO-ARM100-Lift-Cube-Play-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.joint_pos_env_cfg:SoArm100CubeCubeLiftEnvCfg_PLAY",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:LiftCubePPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
diff --git a/source/SO_100/SO_100/tasks/lift/agents/__init__.py b/source/SO_100/SO_100/tasks/lift/agents/__init__.py
deleted file mode 100644
index eb03397..0000000
--- a/source/SO_100/SO_100/tasks/lift/agents/__init__.py
+++ /dev/null
@@ -1,9 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
diff --git a/source/SO_100/SO_100/tasks/lift/agents/rsl_rl_ppo_cfg.py b/source/SO_100/SO_100/tasks/lift/agents/rsl_rl_ppo_cfg.py
deleted file mode 100644
index 27fa0d9..0000000
--- a/source/SO_100/SO_100/tasks/lift/agents/rsl_rl_ppo_cfg.py
+++ /dev/null
@@ -1,45 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from isaaclab.utils import configclass
-from isaaclab_rl.rsl_rl import (
-    RslRlOnPolicyRunnerCfg,
-    RslRlPpoActorCriticCfg,
-    RslRlPpoAlgorithmCfg,
-)
-
-
-@configclass
-class LiftCubePPORunnerCfg(RslRlOnPolicyRunnerCfg):
-    num_steps_per_env = 24
-    max_iterations = 1500
-    save_interval = 50
-    experiment_name = "lift"
-    empirical_normalization = False
-    policy = RslRlPpoActorCriticCfg(
-        init_noise_std=1.0,
-        actor_hidden_dims=[256, 128, 64],
-        critic_hidden_dims=[256, 128, 64],
-        activation="elu",
-    )
-    algorithm = RslRlPpoAlgorithmCfg(
-        value_loss_coef=1.0,
-        use_clipped_value_loss=True,
-        clip_param=0.2,
-        entropy_coef=0.006,
-        num_learning_epochs=5,
-        num_mini_batches=4,
-        learning_rate=1.0e-4,
-        schedule="adaptive",
-        gamma=0.98,
-        lam=0.95,
-        desired_kl=0.01,
-        max_grad_norm=1.0,
-    )
diff --git a/source/SO_100/SO_100/tasks/lift/joint_pos_env_cfg.py b/source/SO_100/SO_100/tasks/lift/joint_pos_env_cfg.py
deleted file mode 100644
index 9c77c91..0000000
--- a/source/SO_100/SO_100/tasks/lift/joint_pos_env_cfg.py
+++ /dev/null
@@ -1,105 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-import isaaclab_tasks.manager_based.manipulation.lift.mdp as mdp
-from isaaclab.assets import RigidObjectCfg
-
-# from isaaclab.managers NotImplementedError
-from isaaclab.sensors.frame_transformer.frame_transformer_cfg import (
-    FrameTransformerCfg,
-    OffsetCfg,
-)
-from isaaclab.sim.schemas.schemas_cfg import RigidBodyPropertiesCfg
-from isaaclab.sim.spawners.from_files.from_files_cfg import UsdFileCfg
-from isaaclab.utils import configclass
-from isaaclab.utils.assets import ISAAC_NUCLEUS_DIR
-from SO_100.robots import SO_ARM100_CFG, SO_ARM100_ROSCON_CFG  # noqa: F401
-from SO_100.tasks.lift.lift_env_cfg import LiftEnvCfg
-
-from isaaclab.markers.config import FRAME_MARKER_CFG  # isort: skip
-
-# ----------------------------------------------------------------
-# --------------- LycheeAI live asset ----------------------------
-# ----------------------------------------------------------------
-
-
-@configclass
-class SoArm100LiftCubeEnvCfg(LiftEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # Set so arm as robot
-        self.scene.robot = SO_ARM100_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
-
-        # override actions
-        self.actions.arm_action = mdp.JointPositionActionCfg(
-            asset_name="robot",
-            joint_names=["Shoulder_Rotation", "Shoulder_Pitch", "Elbow", "Wrist_Pitch", "Wrist_Roll"],
-            scale=0.5,
-            use_default_offset=True,
-        )
-        self.actions.gripper_action = mdp.BinaryJointPositionActionCfg(
-            asset_name="robot",
-            joint_names=["Gripper"],
-            open_command_expr={"Gripper": 0.5},
-            close_command_expr={"Gripper": 0.0},
-        )
-        # Set the body name for the end effector
-        self.commands.object_pose.body_name = ["Fixed_Gripper"]
-
-        # Set Cube as object
-        self.scene.object = RigidObjectCfg(
-            prim_path="{ENV_REGEX_NS}/Object",
-            init_state=RigidObjectCfg.InitialStateCfg(pos=[0.2, 0.0, 0.015], rot=[1, 0, 0, 0]),
-            spawn=UsdFileCfg(
-                usd_path=f"{ISAAC_NUCLEUS_DIR}/Props/Blocks/DexCube/dex_cube_instanceable.usd",
-                scale=(0.3, 0.3, 0.3),
-                rigid_props=RigidBodyPropertiesCfg(
-                    solver_position_iteration_count=16,
-                    solver_velocity_iteration_count=1,
-                    max_angular_velocity=1000.0,
-                    max_linear_velocity=1000.0,
-                    max_depenetration_velocity=5.0,
-                    disable_gravity=False,
-                ),
-            ),
-        )
-
-        # Listens to the required transforms
-        marker_cfg = FRAME_MARKER_CFG.copy()
-        marker_cfg.markers["frame"].scale = (0.05, 0.05, 0.05)
-        marker_cfg.prim_path = "/Visuals/FrameTransformer"
-        self.scene.ee_frame = FrameTransformerCfg(
-            prim_path="{ENV_REGEX_NS}/Robot/Base",
-            debug_vis=False,
-            visualizer_cfg=marker_cfg,
-            target_frames=[
-                FrameTransformerCfg.FrameCfg(
-                    prim_path="{ENV_REGEX_NS}/Robot/Fixed_Gripper",
-                    name="end_effector",
-                    offset=OffsetCfg(
-                        pos=[0.01, 0.0, 0.1],
-                    ),
-                ),
-            ],
-        )
-
-
-@configclass
-class SoArm100LiftCubeEnvCfg_PLAY(SoArm100LiftCubeEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-        # make a smaller scene for play
-        self.scene.num_envs = 50
-        self.scene.env_spacing = 2.5
-        # disable randomization for play
-        self.observations.policy.enable_corruption = False
diff --git a/source/SO_100/SO_100/tasks/lift/lift_env_cfg.py b/source/SO_100/SO_100/tasks/lift/lift_env_cfg.py
deleted file mode 100644
index e8c59f8..0000000
--- a/source/SO_100/SO_100/tasks/lift/lift_env_cfg.py
+++ /dev/null
@@ -1,245 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from dataclasses import MISSING
-
-import isaaclab.sim as sim_utils
-
-# from . import mdp
-import isaaclab_tasks.manager_based.manipulation.lift.mdp as mdp
-from isaaclab.assets import (
-    ArticulationCfg,
-    AssetBaseCfg,
-    DeformableObjectCfg,
-    RigidObjectCfg,
-)
-from isaaclab.envs import ManagerBasedRLEnvCfg
-from isaaclab.managers import CurriculumTermCfg as CurrTerm
-from isaaclab.managers import EventTermCfg as EventTerm
-from isaaclab.managers import ObservationGroupCfg as ObsGroup
-from isaaclab.managers import ObservationTermCfg as ObsTerm
-from isaaclab.managers import RewardTermCfg as RewTerm
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.managers import TerminationTermCfg as DoneTerm
-from isaaclab.scene import InteractiveSceneCfg
-from isaaclab.sensors.frame_transformer.frame_transformer_cfg import FrameTransformerCfg
-from isaaclab.sim.spawners.from_files.from_files_cfg import GroundPlaneCfg, UsdFileCfg
-from isaaclab.utils import configclass
-from isaaclab.utils.assets import ISAAC_NUCLEUS_DIR
-
-# from isaaclab.utils.offset import OffsetCfg
-# from isaaclab.utils.noise import AdditiveUniformNoiseCfg as Unoise
-# from isaaclab.utils.visualizer import FRAME_MARKER_CFG
-# from isaaclab.utils.assets import RigidBodyPropertiesCfg
-
-
-##
-# Scene definition
-##
-
-
-@configclass
-class ObjectTableSceneCfg(InteractiveSceneCfg):
-    """Configuration for the lift scene with a robot and a object.
-    This is the abstract base implementation, the exact scene is defined in the derived classes
-    which need to set the target object, robot and end-effector frames
-    """
-
-    # robots: will be populated by agent env cfg
-    robot: ArticulationCfg = MISSING
-    # end-effector sensor: will be populated by agent env cfg
-    ee_frame: FrameTransformerCfg = MISSING
-    # target object: will be populated by agent env cfg
-    object: RigidObjectCfg | DeformableObjectCfg = MISSING
-
-    # Table
-    table = AssetBaseCfg(
-        prim_path="{ENV_REGEX_NS}/Table",
-        init_state=AssetBaseCfg.InitialStateCfg(pos=[0.5, 0, 0], rot=[0.707, 0, 0, 0.707]),
-        spawn=UsdFileCfg(usd_path=f"{ISAAC_NUCLEUS_DIR}/Props/Mounts/SeattleLabTable/table_instanceable.usd"),
-    )
-
-    # plane
-    plane = AssetBaseCfg(
-        prim_path="/World/GroundPlane",
-        init_state=AssetBaseCfg.InitialStateCfg(pos=[0, 0, -1.05]),
-        spawn=GroundPlaneCfg(),
-    )
-
-    # lights
-    light = AssetBaseCfg(
-        prim_path="/World/light",
-        spawn=sim_utils.DomeLightCfg(color=(0.75, 0.75, 0.75), intensity=3000.0),
-    )
-
-
-##
-# MDP settings
-##
-
-
-@configclass
-class CommandsCfg:
-    """Command terms for the MDP."""
-
-    object_pose = mdp.UniformPoseCommandCfg(
-        asset_name="robot",
-        body_name=MISSING,  # will be set by agent env cfg
-        resampling_time_range=(5.0, 5.0),
-        debug_vis=True,
-        ranges=mdp.UniformPoseCommandCfg.Ranges(
-            pos_x=(-0.1, 0.1),
-            pos_y=(-0.3, -0.1),
-            pos_z=(0.2, 0.35),
-            roll=(0.0, 0.0),
-            pitch=(0.0, 0.0),
-            yaw=(0.0, 0.0),
-        ),
-    )
-
-
-@configclass
-class ActionsCfg:
-    """Action specifications for the MDP."""
-
-    # will be set by agent env cfg
-    arm_action: mdp.JointPositionActionCfg | mdp.DifferentialInverseKinematicsActionCfg = MISSING
-    gripper_action: mdp.BinaryJointPositionActionCfg = MISSING
-
-
-@configclass
-class ObservationsCfg:
-    """Observation specifications for the MDP."""
-
-    @configclass
-    class PolicyCfg(ObsGroup):
-        """Observations for policy group."""
-
-        joint_pos = ObsTerm(func=mdp.joint_pos_rel)
-        joint_vel = ObsTerm(func=mdp.joint_vel_rel)
-        object_position = ObsTerm(func=mdp.object_position_in_robot_root_frame)
-        target_object_position = ObsTerm(func=mdp.generated_commands, params={"command_name": "object_pose"})
-        actions = ObsTerm(func=mdp.last_action)
-
-        def __post_init__(self):
-            self.enable_corruption = True
-            self.concatenate_terms = True
-
-    # observation groups
-    policy: PolicyCfg = PolicyCfg()
-
-
-@configclass
-class EventCfg:
-    """Configuration for events."""
-
-    reset_all = EventTerm(func=mdp.reset_scene_to_default, mode="reset")
-
-    reset_object_position = EventTerm(
-        func=mdp.reset_root_state_uniform,
-        mode="reset",
-        params={
-            "pose_range": {"x": (-0.1, 0.1), "y": (-0.2, 0.2), "z": (0.0, 0.0)},
-            "velocity_range": {},
-            "asset_cfg": SceneEntityCfg("object", body_names="Object"),
-        },
-    )
-
-
-@configclass
-class RewardsCfg:
-    """Reward terms for the MDP."""
-
-    reaching_object = RewTerm(func=mdp.object_ee_distance, params={"std": 0.05}, weight=1.0)
-
-    lifting_object = RewTerm(func=mdp.object_is_lifted, params={"minimal_height": 0.04}, weight=15.0)
-
-    object_goal_tracking = RewTerm(
-        func=mdp.object_goal_distance,
-        params={"std": 0.3, "minimal_height": 0.04, "command_name": "object_pose"},
-        weight=16.0,
-    )
-
-    object_goal_tracking_fine_grained = RewTerm(
-        func=mdp.object_goal_distance,
-        params={"std": 0.05, "minimal_height": 0.04, "command_name": "object_pose"},
-        weight=5.0,
-    )
-
-    # action penalty
-    action_rate = RewTerm(func=mdp.action_rate_l2, weight=-1e-4)
-
-    joint_vel = RewTerm(
-        func=mdp.joint_vel_l2,
-        weight=-1e-4,
-        params={"asset_cfg": SceneEntityCfg("robot")},
-    )
-
-
-@configclass
-class TerminationsCfg:
-    """Termination terms for the MDP."""
-
-    time_out = DoneTerm(func=mdp.time_out, time_out=True)
-
-    object_dropping = DoneTerm(
-        func=mdp.root_height_below_minimum, params={"minimum_height": -0.05, "asset_cfg": SceneEntityCfg("object")}
-    )
-
-
-@configclass
-class CurriculumCfg:
-    """Curriculum terms for the MDP."""
-
-    action_rate = CurrTerm(
-        func=mdp.modify_reward_weight, params={"term_name": "action_rate", "weight": -1e-1, "num_steps": 10000}
-    )
-
-    joint_vel = CurrTerm(
-        func=mdp.modify_reward_weight, params={"term_name": "joint_vel", "weight": -1e-1, "num_steps": 10000}
-    )
-
-
-##
-# Environment configuration
-##
-
-
-@configclass
-class LiftEnvCfg(ManagerBasedRLEnvCfg):
-    """Configuration for the lifting environment."""
-
-    # Scene settings
-    scene: ObjectTableSceneCfg = ObjectTableSceneCfg(num_envs=4096, env_spacing=2.5)
-    # Basic settings
-    observations: ObservationsCfg = ObservationsCfg()
-    actions: ActionsCfg = ActionsCfg()
-    commands: CommandsCfg = CommandsCfg()
-    # MDP settings
-    rewards: RewardsCfg = RewardsCfg()
-    terminations: TerminationsCfg = TerminationsCfg()
-    events: EventCfg = EventCfg()
-    curriculum: CurriculumCfg = CurriculumCfg()
-
-    def __post_init__(self):
-        """Post initialization."""
-        # general settings
-        self.decimation = 2
-        self.episode_length_s = 5.0
-        self.viewer.eye = (2.5, 2.5, 1.5)
-        # simulation settings
-        self.sim.dt = 0.01  # 100Hz
-        self.sim.render_interval = self.decimation
-
-        self.sim.physx.bounce_threshold_velocity = 0.2
-        self.sim.physx.bounce_threshold_velocity = 0.01
-        self.sim.physx.gpu_found_lost_aggregate_pairs_capacity = 1024 * 1024 * 4
-        self.sim.physx.gpu_total_aggregate_pairs_capacity = 16 * 1024
-        self.sim.physx.friction_correlation_distance = 0.00625
diff --git a/source/SO_100/SO_100/tasks/lift/mdp/__init__.py b/source/SO_100/SO_100/tasks/lift/mdp/__init__.py
deleted file mode 100644
index 7d8350b..0000000
--- a/source/SO_100/SO_100/tasks/lift/mdp/__init__.py
+++ /dev/null
@@ -1,17 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""This sub-module contains the functions that are specific to the lift environments."""
-
-from isaaclab.envs.mdp import *  # noqa: F401, F403
-
-from .observations import *  # noqa: F401, F403
-from .rewards import *  # noqa: F401, F403
-from .terminations import *  # noqa: F401, F403
diff --git a/source/SO_100/SO_100/tasks/lift/mdp/observations.py b/source/SO_100/SO_100/tasks/lift/mdp/observations.py
deleted file mode 100644
index de10c34..0000000
--- a/source/SO_100/SO_100/tasks/lift/mdp/observations.py
+++ /dev/null
@@ -1,36 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-import torch
-from isaaclab.assets import RigidObject
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.utils.math import subtract_frame_transforms
-
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-
-
-def object_position_in_robot_root_frame(
-    env: ManagerBasedRLEnv,
-    robot_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-) -> torch.Tensor:
-    """The position of the object in the robot's root frame."""
-    robot: RigidObject = env.scene[robot_cfg.name]
-    object: RigidObject = env.scene[object_cfg.name]
-    object_pos_w = object.data.root_pos_w[:, :3]
-    object_pos_b, _ = subtract_frame_transforms(
-        robot.data.root_state_w[:, :3], robot.data.root_state_w[:, 3:7], object_pos_w
-    )
-    return object_pos_b
diff --git a/source/SO_100/SO_100/tasks/lift/mdp/rewards.py b/source/SO_100/SO_100/tasks/lift/mdp/rewards.py
deleted file mode 100644
index 9c5911f..0000000
--- a/source/SO_100/SO_100/tasks/lift/mdp/rewards.py
+++ /dev/null
@@ -1,88 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-import torch
-from isaaclab.assets import RigidObject
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.sensors import FrameTransformer
-from isaaclab.utils.math import combine_frame_transforms
-
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-
-
-def object_is_lifted(
-    env: ManagerBasedRLEnv, minimal_height: float, object_cfg: SceneEntityCfg = SceneEntityCfg("object")
-) -> torch.Tensor:
-    """Reward the agent for lifting the object above the minimal height."""
-    object: RigidObject = env.scene[object_cfg.name]
-    return torch.where(object.data.root_pos_w[:, 2] > minimal_height, 1.0, 0.0)
-
-
-def object_ee_distance(
-    env: ManagerBasedRLEnv,
-    std: float,
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-    ee_frame_cfg: SceneEntityCfg = SceneEntityCfg("ee_frame"),
-) -> torch.Tensor:
-    """Reward the agent for reaching the object using tanh-kernel."""
-    # extract the used quantities (to enable type-hinting)
-    object: RigidObject = env.scene[object_cfg.name]
-    ee_frame: FrameTransformer = env.scene[ee_frame_cfg.name]
-    # Target object position: (num_envs, 3)
-    cube_pos_w = object.data.root_pos_w
-    # End-effector position: (num_envs, 3)
-    ee_w = ee_frame.data.target_pos_w[..., 0, :]
-    # Distance of the end-effector to the object: (num_envs,)
-    object_ee_distance = torch.norm(cube_pos_w - ee_w, dim=1)
-
-    return 1 - torch.tanh(object_ee_distance / std)
-
-
-def object_goal_distance(
-    env: ManagerBasedRLEnv,
-    std: float,
-    minimal_height: float,
-    command_name: str,
-    robot_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-) -> torch.Tensor:
-    """Reward the agent for tracking the goal pose using tanh-kernel."""
-    # extract the used quantities (to enable type-hinting)
-    robot: RigidObject = env.scene[robot_cfg.name]
-    object: RigidObject = env.scene[object_cfg.name]
-    command = env.command_manager.get_command(command_name)
-    # compute the desired position in the world frame
-    des_pos_b = command[:, :3]
-    des_pos_w, _ = combine_frame_transforms(robot.data.root_state_w[:, :3], robot.data.root_state_w[:, 3:7], des_pos_b)
-    # distance of the end-effector to the object: (num_envs,)
-    distance = torch.norm(des_pos_w - object.data.root_pos_w[:, :3], dim=1)
-    # rewarded if the object is lifted above the threshold
-    return (object.data.root_pos_w[:, 2] > minimal_height) * (1 - torch.tanh(distance / std))
-
-
-def object_ee_distance_and_lifted(
-    env: ManagerBasedRLEnv,
-    std: float,
-    minimal_height: float,
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-    ee_frame_cfg: SceneEntityCfg = SceneEntityCfg("ee_frame"),
-) -> torch.Tensor:
-    """Combined reward for reaching the object AND lifting it."""
-    # Get reaching reward
-    reach_reward = object_ee_distance(env, std, object_cfg, ee_frame_cfg)
-    # Get lifting reward
-    lift_reward = object_is_lifted(env, minimal_height, object_cfg)
-    # Combine rewards multiplicatively
-    return reach_reward * lift_reward
diff --git a/source/SO_100/SO_100/tasks/lift/mdp/terminations.py b/source/SO_100/SO_100/tasks/lift/mdp/terminations.py
deleted file mode 100644
index bc35724..0000000
--- a/source/SO_100/SO_100/tasks/lift/mdp/terminations.py
+++ /dev/null
@@ -1,58 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Common functions that can be used to activate certain terminations for the lift task.
-
-The functions can be passed to the :class:`isaaclab.managers.TerminationTermCfg` object to enable
-the termination introduced by the function.
-"""
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-import torch
-from isaaclab.assets import RigidObject
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.utils.math import combine_frame_transforms
-
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-
-
-def object_reached_goal(
-    env: ManagerBasedRLEnv,
-    command_name: str = "object_pose",
-    threshold: float = 0.02,
-    robot_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-) -> torch.Tensor:
-    """Termination condition for the object reaching the goal position.
-
-    Args:
-        env: The environment.
-        command_name: The name of the command that is used to control the object.
-        threshold: The threshold for the object to reach the goal position. Defaults to 0.02.
-        robot_cfg: The robot configuration. Defaults to SceneEntityCfg("robot").
-        object_cfg: The object configuration. Defaults to SceneEntityCfg("object").
-
-    """
-    # extract the used quantities (to enable type-hinting)
-    robot: RigidObject = env.scene[robot_cfg.name]
-    object: RigidObject = env.scene[object_cfg.name]
-    command = env.command_manager.get_command(command_name)
-    # compute the desired position in the world frame
-    des_pos_b = command[:, :3]
-    des_pos_w, _ = combine_frame_transforms(robot.data.root_state_w[:, :3], robot.data.root_state_w[:, 3:7], des_pos_b)
-    # distance of the end-effector to the object: (num_envs,)
-    distance = torch.norm(des_pos_w - object.data.root_pos_w[:, :3], dim=1)
-
-    # rewarded if the object is lifted above the threshold
-    return distance < threshold
diff --git a/source/SO_100/SO_100/tasks/reach/__init__.py b/source/SO_100/SO_100/tasks/reach/__init__.py
deleted file mode 100644
index 8f905da..0000000
--- a/source/SO_100/SO_100/tasks/reach/__init__.py
+++ /dev/null
@@ -1,91 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-import gymnasium as gym
-
-from . import agents
-
-##
-# Register Gym environments.
-##
-
-# ----------------------------------------------------------------
-# --------------- LycheeAI live asset ----------------------------
-# ----------------------------------------------------------------
-
-gym.register(
-    id="SO-ARM100-Reach-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.joint_pos_env_cfg:SoArm100ReachEnvCfg",
-        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_ppo_cfg.yaml",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:ReachPPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
-
-gym.register(
-    id="SO-ARM100-Reach-Play-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.joint_pos_env_cfg:SoArm100ReachEnvCfg_PLAY",
-        "skrl_cfg_entry_point": f"{agents.__name__}:skrl_ppo_cfg.yaml",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:ReachPPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
-
-# ----------------------------------------------------------------
-# --------------- ROSCON ES 2025 asset ---------------------------
-# ----------------------------------------------------------------
-
-# Joint position controller
-
-gym.register(
-    id="SO-ARM100-Reach-ROSCON-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.joint_pos_env_cfg:SoArm100ReachRosConEnvCfg",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:ReachRosConPPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
-
-gym.register(
-    id="SO-ARM100-Reach-ROSCON-Play-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.joint_pos_env_cfg:SoArm100ReachRosConEnvCfg_PLAY",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:ReachRosConPPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
-
-# Relative IK controller
-
-gym.register(
-    id="SO-ARM100-Reach-ROSCON-IK-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.ik_rel_env_cfg:SoArm100ReachRosCon_IK_EnvCfg",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:ReachRosConIKPPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
-
-gym.register(
-    id="SO-ARM100-Reach-ROSCON-IK-Play-v0",
-    entry_point="isaaclab.envs:ManagerBasedRLEnv",
-    kwargs={
-        "env_cfg_entry_point": f"{__name__}.ik_rel_env_cfg:SoArm100ReachRosCon_IK_EnvCfg_PLAY",
-        "rsl_rl_cfg_entry_point": f"{agents.__name__}.rsl_rl_ppo_cfg:ReachRosConIKPPORunnerCfg",
-    },
-    disable_env_checker=True,
-)
diff --git a/source/SO_100/SO_100/tasks/reach/agents/__init__.py b/source/SO_100/SO_100/tasks/reach/agents/__init__.py
deleted file mode 100644
index eb03397..0000000
--- a/source/SO_100/SO_100/tasks/reach/agents/__init__.py
+++ /dev/null
@@ -1,9 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
diff --git a/source/SO_100/SO_100/tasks/reach/agents/rsl_rl_ppo_cfg.py b/source/SO_100/SO_100/tasks/reach/agents/rsl_rl_ppo_cfg.py
deleted file mode 100644
index 0b7de74..0000000
--- a/source/SO_100/SO_100/tasks/reach/agents/rsl_rl_ppo_cfg.py
+++ /dev/null
@@ -1,109 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from isaaclab.utils import configclass
-from isaaclab_rl.rsl_rl import (
-    RslRlOnPolicyRunnerCfg,
-    RslRlPpoActorCriticCfg,
-    RslRlPpoAlgorithmCfg,
-)
-
-
-@configclass
-class ReachPPORunnerCfg(RslRlOnPolicyRunnerCfg):
-    num_steps_per_env = 24
-    max_iterations = 1000
-    save_interval = 50
-    experiment_name = "reach"
-    run_name = ""
-    resume = False
-    empirical_normalization = False
-    policy = RslRlPpoActorCriticCfg(
-        init_noise_std=1.0,
-        actor_hidden_dims=[64, 64],
-        critic_hidden_dims=[64, 64],
-        activation="elu",
-    )
-    algorithm = RslRlPpoAlgorithmCfg(
-        value_loss_coef=1.0,
-        use_clipped_value_loss=True,
-        clip_param=0.2,
-        entropy_coef=0.001,
-        num_learning_epochs=8,
-        num_mini_batches=4,
-        learning_rate=1.0e-3,
-        schedule="adaptive",
-        gamma=0.99,
-        lam=0.95,
-        desired_kl=0.01,
-        max_grad_norm=1.0,
-    )
-
-
-@configclass
-class ReachRosConPPORunnerCfg(RslRlOnPolicyRunnerCfg):
-    num_steps_per_env = 24
-    max_iterations = 1000
-    save_interval = 50
-    experiment_name = "reach_roscon"
-    run_name = ""
-    resume = False
-    empirical_normalization = False
-    policy = RslRlPpoActorCriticCfg(
-        init_noise_std=1.0,
-        actor_hidden_dims=[64, 64],
-        critic_hidden_dims=[64, 64],
-        activation="elu",
-    )
-    algorithm = RslRlPpoAlgorithmCfg(
-        value_loss_coef=1.0,
-        use_clipped_value_loss=True,
-        clip_param=0.2,
-        entropy_coef=0.001,
-        num_learning_epochs=8,
-        num_mini_batches=4,
-        learning_rate=1.0e-3,
-        schedule="adaptive",
-        gamma=0.99,
-        lam=0.95,
-        desired_kl=0.01,
-        max_grad_norm=1.0,
-    )
-
-
-@configclass
-class ReachRosConIKPPORunnerCfg(RslRlOnPolicyRunnerCfg):
-    num_steps_per_env = 24
-    max_iterations = 1000
-    save_interval = 50
-    experiment_name = "reach_roscon_ik"
-    run_name = ""
-    resume = False
-    empirical_normalization = False
-    policy = RslRlPpoActorCriticCfg(
-        init_noise_std=1.0,
-        actor_hidden_dims=[64, 64],
-        critic_hidden_dims=[64, 64],
-        activation="elu",
-    )
-    algorithm = RslRlPpoAlgorithmCfg(
-        value_loss_coef=1.0,
-        use_clipped_value_loss=True,
-        clip_param=0.2,
-        entropy_coef=0.001,
-        num_learning_epochs=8,
-        num_mini_batches=4,
-        learning_rate=1.0e-3,
-        schedule="adaptive",
-        gamma=0.99,
-        lam=0.95,
-        desired_kl=0.01,
-        max_grad_norm=1.0,
-    )
diff --git a/source/SO_100/SO_100/tasks/reach/agents/skrl_ppo_cfg.yaml b/source/SO_100/SO_100/tasks/reach/agents/skrl_ppo_cfg.yaml
deleted file mode 100644
index 15e2c15..0000000
--- a/source/SO_100/SO_100/tasks/reach/agents/skrl_ppo_cfg.yaml
+++ /dev/null
@@ -1,80 +0,0 @@
-seed: 42
-
-
-# Models are instantiated using skrl's model instantiator utility
-# https://skrl.readthedocs.io/en/latest/api/utils/model_instantiators.html
-models:
-  separate: False
-  policy:  # see gaussian_model parameters
-    class: GaussianMixin
-    clip_actions: False
-    clip_log_std: True
-    min_log_std: -20.0
-    max_log_std: 2.0
-    initial_log_std: 0.0
-    network:
-      - name: net
-        input: STATES
-        layers: [64, 64]
-        activations: elu
-    output: ACTIONS
-  value:  # see deterministic_model parameters
-    class: DeterministicMixin
-    clip_actions: False
-    network:
-      - name: net
-        input: STATES
-        layers: [64, 64]
-        activations: elu
-    output: ONE
-
-
-# Rollout memory
-# https://skrl.readthedocs.io/en/latest/api/memories/random.html
-memory:
-  class: RandomMemory
-  memory_size: -1  # automatically determined (same as agent:rollouts)
-
-
-# PPO agent configuration (field names are from PPO_DEFAULT_CONFIG)
-# https://skrl.readthedocs.io/en/latest/api/agents/ppo.html
-agent:
-  class: PPO
-  rollouts: 24
-  learning_epochs: 5
-  mini_batches: 4
-  discount_factor: 0.99
-  lambda: 0.95
-  learning_rate: 1.0e-03
-  learning_rate_scheduler: KLAdaptiveLR
-  learning_rate_scheduler_kwargs:
-    kl_threshold: 0.01
-  state_preprocessor: RunningStandardScaler
-  state_preprocessor_kwargs: null
-  value_preprocessor: RunningStandardScaler
-  value_preprocessor_kwargs: null
-  random_timesteps: 0
-  learning_starts: 0
-  grad_norm_clip: 1.0
-  ratio_clip: 0.2
-  value_clip: 0.2
-  clip_predicted_values: True
-  entropy_loss_scale: 0.01
-  value_loss_scale: 1.0
-  kl_threshold: 0.0
-  rewards_shaper_scale: 1.0
-  time_limit_bootstrap: False
-  # logging and checkpoint
-  experiment:
-    directory: "reach"
-    experiment_name: "reach"
-    write_interval: auto
-    checkpoint_interval: auto
-
-
-# Sequential trainer
-# https://skrl.readthedocs.io/en/latest/api/trainers/sequential.html
-trainer:
-  class: SequentialTrainer
-  timesteps: 24000
-  environment_info: log
diff --git a/source/SO_100/SO_100/tasks/reach/ik_rel_env_cfg.py b/source/SO_100/SO_100/tasks/reach/ik_rel_env_cfg.py
deleted file mode 100644
index 0bf4011..0000000
--- a/source/SO_100/SO_100/tasks/reach/ik_rel_env_cfg.py
+++ /dev/null
@@ -1,63 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from isaaclab.controllers.differential_ik_cfg import DifferentialIKControllerCfg
-from isaaclab.envs.mdp.actions.actions_cfg import DifferentialInverseKinematicsActionCfg
-from isaaclab.utils import configclass
-
-##
-# Pre-defined configs
-##
-from SO_100.robots import SO_ARM100_ROSCON_HIGH_PD_CFG  # noqa: F401
-
-from .joint_pos_env_cfg import SoArm100ReachRosConEnvCfg
-
-# ----------------------------------------------------------------
-# --------------- ROSCON ES 2025 asset ---------------------------
-# ----------------------------------------------------------------
-
-
-@configclass
-class SoArm100ReachRosCon_IK_EnvCfg(SoArm100ReachRosConEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # Set Franka as robot
-        # We switch here to a stiffer PD controller for IK tracking to be better.
-        self.scene.robot = SO_ARM100_ROSCON_HIGH_PD_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
-
-        # Set actions for the specific robot type (franka)
-        self.actions.arm_action = DifferentialInverseKinematicsActionCfg(
-            asset_name="robot",
-            joint_names=[
-                "shoulder_pan_joint",
-                "shoulder_lift_joint",
-                "elbow_joint",
-                "wrist_pitch_joint",
-                "wrist_roll_joint",
-            ],
-            body_name="wrist_2_link",
-            controller=DifferentialIKControllerCfg(command_type="pose", use_relative_mode=True, ik_method="dls"),
-            scale=0.5,
-            body_offset=DifferentialInverseKinematicsActionCfg.OffsetCfg(pos=[-0.005, -0.1, 0.0]),
-        )
-
-
-@configclass
-class SoArm100ReachRosCon_IK_EnvCfg_PLAY(SoArm100ReachRosCon_IK_EnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-        # make a smaller scene for play
-        self.scene.num_envs = 50
-        self.scene.env_spacing = 2.5
-        # disable randomization for play
-        self.observations.policy.enable_corruption = False
diff --git a/source/SO_100/SO_100/tasks/reach/joint_pos_env_cfg.py b/source/SO_100/SO_100/tasks/reach/joint_pos_env_cfg.py
deleted file mode 100644
index 2aee181..0000000
--- a/source/SO_100/SO_100/tasks/reach/joint_pos_env_cfg.py
+++ /dev/null
@@ -1,114 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers (https://github.com/isaac-sim/IsaacLab/blob/main/CONTRIBUTORS.md).
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-
-# import mdp
-import isaaclab_tasks.manager_based.manipulation.reach.mdp as mdp
-from isaaclab.utils import configclass
-from SO_100.robots import SO_ARM100_CFG, SO_ARM100_ROSCON_CFG  # noqa: F401
-from SO_100.tasks.reach.reach_env_cfg import ReachEnvCfg
-
-##
-# Scene definition
-##
-
-# ----------------------------------------------------------------
-# --------------- LycheeAI live asset ----------------------------
-# ----------------------------------------------------------------
-
-
-@configclass
-class SoArm100ReachEnvCfg(ReachEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # switch robot to franka
-        self.scene.robot = SO_ARM100_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
-        # override rewards
-        self.rewards.end_effector_position_tracking.params["asset_cfg"].body_names = ["Fixed_Gripper"]
-        self.rewards.end_effector_position_tracking_fine_grained.params["asset_cfg"].body_names = ["Fixed_Gripper"]
-        self.rewards.end_effector_orientation_tracking.params["asset_cfg"].body_names = ["Fixed_Gripper"]
-
-        # TODO: reorient command target
-
-        # override actions
-        self.actions.arm_action = mdp.JointPositionActionCfg(
-            asset_name="robot",
-            joint_names=["Shoulder_Rotation", "Shoulder_Pitch", "Elbow", "Wrist_Pitch", "Wrist_Roll"],
-            scale=0.5,
-            use_default_offset=True,
-        )
-        # override command generator body
-        # end-effector is along z-direction
-        self.commands.ee_pose.body_name = ["Fixed_Gripper"]
-        # self.commands.ee_pose.ranges.pitch = (math.pi, math.pi)
-
-
-@configclass
-class SoArm100ReachEnvCfg_PLAY(SoArm100ReachEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-        # make a smaller scene for play
-        self.scene.num_envs = 50
-        self.scene.env_spacing = 2.5
-        # disable randomization for play
-        self.observations.policy.enable_corruption = False
-
-
-# ----------------------------------------------------------------
-# --------------- ROSCON ES 2025 asset ---------------------------
-# ----------------------------------------------------------------
-
-
-@configclass
-class SoArm100ReachRosConEnvCfg(ReachEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-
-        # switch robot to franka
-        self.scene.robot = SO_ARM100_ROSCON_CFG.replace(prim_path="{ENV_REGEX_NS}/Robot")
-        # override rewards
-        self.rewards.end_effector_position_tracking.params["asset_cfg"].body_names = ["wrist_2_link"]
-        self.rewards.end_effector_position_tracking_fine_grained.params["asset_cfg"].body_names = ["wrist_2_link"]
-        self.rewards.end_effector_orientation_tracking.params["asset_cfg"].body_names = ["wrist_2_link"]
-
-        self.rewards.end_effector_orientation_tracking.weight = 0.0
-
-        # override actions
-        self.actions.arm_action = mdp.JointPositionActionCfg(
-            asset_name="robot",
-            joint_names=[".*"],
-            scale=0.5,
-            use_default_offset=True,
-        )
-        # override command generator body
-        # end-effector is along z-direction
-        self.commands.ee_pose.body_name = ["wrist_2_link"]
-        # self.commands.ee_pose.ranges.pitch = (math.pi, math.pi)
-
-
-@configclass
-class SoArm100ReachRosConEnvCfg_PLAY(SoArm100ReachRosConEnvCfg):
-    def __post_init__(self):
-        # post init of parent
-        super().__post_init__()
-        # make a smaller scene for play
-        self.scene.num_envs = 50
-        self.scene.env_spacing = 2.5
-        # disable randomization for play
-        self.observations.policy.enable_corruption = False
diff --git a/source/SO_100/SO_100/tasks/reach/mdp/__init__.py b/source/SO_100/SO_100/tasks/reach/mdp/__init__.py
deleted file mode 100644
index 7d8350b..0000000
--- a/source/SO_100/SO_100/tasks/reach/mdp/__init__.py
+++ /dev/null
@@ -1,17 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""This sub-module contains the functions that are specific to the lift environments."""
-
-from isaaclab.envs.mdp import *  # noqa: F401, F403
-
-from .observations import *  # noqa: F401, F403
-from .rewards import *  # noqa: F401, F403
-from .terminations import *  # noqa: F401, F403
diff --git a/source/SO_100/SO_100/tasks/reach/mdp/observations.py b/source/SO_100/SO_100/tasks/reach/mdp/observations.py
deleted file mode 100644
index de10c34..0000000
--- a/source/SO_100/SO_100/tasks/reach/mdp/observations.py
+++ /dev/null
@@ -1,36 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-import torch
-from isaaclab.assets import RigidObject
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.utils.math import subtract_frame_transforms
-
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-
-
-def object_position_in_robot_root_frame(
-    env: ManagerBasedRLEnv,
-    robot_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-) -> torch.Tensor:
-    """The position of the object in the robot's root frame."""
-    robot: RigidObject = env.scene[robot_cfg.name]
-    object: RigidObject = env.scene[object_cfg.name]
-    object_pos_w = object.data.root_pos_w[:, :3]
-    object_pos_b, _ = subtract_frame_transforms(
-        robot.data.root_state_w[:, :3], robot.data.root_state_w[:, 3:7], object_pos_w
-    )
-    return object_pos_b
diff --git a/source/SO_100/SO_100/tasks/reach/mdp/rewards.py b/source/SO_100/SO_100/tasks/reach/mdp/rewards.py
deleted file mode 100644
index 9c5911f..0000000
--- a/source/SO_100/SO_100/tasks/reach/mdp/rewards.py
+++ /dev/null
@@ -1,88 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-import torch
-from isaaclab.assets import RigidObject
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.sensors import FrameTransformer
-from isaaclab.utils.math import combine_frame_transforms
-
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-
-
-def object_is_lifted(
-    env: ManagerBasedRLEnv, minimal_height: float, object_cfg: SceneEntityCfg = SceneEntityCfg("object")
-) -> torch.Tensor:
-    """Reward the agent for lifting the object above the minimal height."""
-    object: RigidObject = env.scene[object_cfg.name]
-    return torch.where(object.data.root_pos_w[:, 2] > minimal_height, 1.0, 0.0)
-
-
-def object_ee_distance(
-    env: ManagerBasedRLEnv,
-    std: float,
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-    ee_frame_cfg: SceneEntityCfg = SceneEntityCfg("ee_frame"),
-) -> torch.Tensor:
-    """Reward the agent for reaching the object using tanh-kernel."""
-    # extract the used quantities (to enable type-hinting)
-    object: RigidObject = env.scene[object_cfg.name]
-    ee_frame: FrameTransformer = env.scene[ee_frame_cfg.name]
-    # Target object position: (num_envs, 3)
-    cube_pos_w = object.data.root_pos_w
-    # End-effector position: (num_envs, 3)
-    ee_w = ee_frame.data.target_pos_w[..., 0, :]
-    # Distance of the end-effector to the object: (num_envs,)
-    object_ee_distance = torch.norm(cube_pos_w - ee_w, dim=1)
-
-    return 1 - torch.tanh(object_ee_distance / std)
-
-
-def object_goal_distance(
-    env: ManagerBasedRLEnv,
-    std: float,
-    minimal_height: float,
-    command_name: str,
-    robot_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-) -> torch.Tensor:
-    """Reward the agent for tracking the goal pose using tanh-kernel."""
-    # extract the used quantities (to enable type-hinting)
-    robot: RigidObject = env.scene[robot_cfg.name]
-    object: RigidObject = env.scene[object_cfg.name]
-    command = env.command_manager.get_command(command_name)
-    # compute the desired position in the world frame
-    des_pos_b = command[:, :3]
-    des_pos_w, _ = combine_frame_transforms(robot.data.root_state_w[:, :3], robot.data.root_state_w[:, 3:7], des_pos_b)
-    # distance of the end-effector to the object: (num_envs,)
-    distance = torch.norm(des_pos_w - object.data.root_pos_w[:, :3], dim=1)
-    # rewarded if the object is lifted above the threshold
-    return (object.data.root_pos_w[:, 2] > minimal_height) * (1 - torch.tanh(distance / std))
-
-
-def object_ee_distance_and_lifted(
-    env: ManagerBasedRLEnv,
-    std: float,
-    minimal_height: float,
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-    ee_frame_cfg: SceneEntityCfg = SceneEntityCfg("ee_frame"),
-) -> torch.Tensor:
-    """Combined reward for reaching the object AND lifting it."""
-    # Get reaching reward
-    reach_reward = object_ee_distance(env, std, object_cfg, ee_frame_cfg)
-    # Get lifting reward
-    lift_reward = object_is_lifted(env, minimal_height, object_cfg)
-    # Combine rewards multiplicatively
-    return reach_reward * lift_reward
diff --git a/source/SO_100/SO_100/tasks/reach/mdp/terminations.py b/source/SO_100/SO_100/tasks/reach/mdp/terminations.py
deleted file mode 100644
index bc35724..0000000
--- a/source/SO_100/SO_100/tasks/reach/mdp/terminations.py
+++ /dev/null
@@ -1,58 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Common functions that can be used to activate certain terminations for the lift task.
-
-The functions can be passed to the :class:`isaaclab.managers.TerminationTermCfg` object to enable
-the termination introduced by the function.
-"""
-
-from __future__ import annotations
-
-from typing import TYPE_CHECKING
-
-import torch
-from isaaclab.assets import RigidObject
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.utils.math import combine_frame_transforms
-
-if TYPE_CHECKING:
-    from isaaclab.envs import ManagerBasedRLEnv
-
-
-def object_reached_goal(
-    env: ManagerBasedRLEnv,
-    command_name: str = "object_pose",
-    threshold: float = 0.02,
-    robot_cfg: SceneEntityCfg = SceneEntityCfg("robot"),
-    object_cfg: SceneEntityCfg = SceneEntityCfg("object"),
-) -> torch.Tensor:
-    """Termination condition for the object reaching the goal position.
-
-    Args:
-        env: The environment.
-        command_name: The name of the command that is used to control the object.
-        threshold: The threshold for the object to reach the goal position. Defaults to 0.02.
-        robot_cfg: The robot configuration. Defaults to SceneEntityCfg("robot").
-        object_cfg: The object configuration. Defaults to SceneEntityCfg("object").
-
-    """
-    # extract the used quantities (to enable type-hinting)
-    robot: RigidObject = env.scene[robot_cfg.name]
-    object: RigidObject = env.scene[object_cfg.name]
-    command = env.command_manager.get_command(command_name)
-    # compute the desired position in the world frame
-    des_pos_b = command[:, :3]
-    des_pos_w, _ = combine_frame_transforms(robot.data.root_state_w[:, :3], robot.data.root_state_w[:, 3:7], des_pos_b)
-    # distance of the end-effector to the object: (num_envs,)
-    distance = torch.norm(des_pos_w - object.data.root_pos_w[:, :3], dim=1)
-
-    # rewarded if the object is lifted above the threshold
-    return distance < threshold
diff --git a/source/SO_100/SO_100/tasks/reach/reach_env_cfg.py b/source/SO_100/SO_100/tasks/reach/reach_env_cfg.py
deleted file mode 100644
index b4fc2de..0000000
--- a/source/SO_100/SO_100/tasks/reach/reach_env_cfg.py
+++ /dev/null
@@ -1,214 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-from dataclasses import MISSING
-
-import isaaclab.sim as sim_utils
-
-# import mdp
-import isaaclab_tasks.manager_based.manipulation.reach.mdp as mdp
-from isaaclab.assets import ArticulationCfg, AssetBaseCfg
-from isaaclab.envs import ManagerBasedRLEnvCfg
-from isaaclab.managers import ActionTermCfg as ActionTerm
-from isaaclab.managers import CurriculumTermCfg as CurrTerm
-from isaaclab.managers import EventTermCfg as EventTerm
-from isaaclab.managers import ObservationGroupCfg as ObsGroup
-from isaaclab.managers import ObservationTermCfg as ObsTerm
-from isaaclab.managers import RewardTermCfg as RewTerm
-from isaaclab.managers import SceneEntityCfg
-from isaaclab.managers import TerminationTermCfg as DoneTerm
-from isaaclab.scene import InteractiveSceneCfg
-from isaaclab.utils import configclass
-from isaaclab.utils.assets import ISAAC_NUCLEUS_DIR
-from isaaclab.utils.noise import AdditiveUniformNoiseCfg as Unoise
-
-##
-# Scene definition
-##
-
-
-@configclass
-class ReachSceneCfg(InteractiveSceneCfg):
-    """Configuration for the scene with a robotic arm."""
-
-    # world
-    ground = AssetBaseCfg(
-        prim_path="/World/ground",
-        spawn=sim_utils.GroundPlaneCfg(),
-        init_state=AssetBaseCfg.InitialStateCfg(pos=(0.0, 0.0, -1.05)),
-    )
-
-    table = AssetBaseCfg(
-        prim_path="{ENV_REGEX_NS}/Table",
-        spawn=sim_utils.UsdFileCfg(
-            usd_path=f"{ISAAC_NUCLEUS_DIR}/Props/Mounts/SeattleLabTable/table_instanceable.usd",
-        ),
-        init_state=AssetBaseCfg.InitialStateCfg(pos=(0.55, 0.0, 0.0), rot=(0.70711, 0.0, 0.0, 0.70711)),
-    )
-
-    # robots
-    robot: ArticulationCfg = MISSING
-
-    # lights
-    light = AssetBaseCfg(
-        prim_path="/World/light",
-        spawn=sim_utils.DomeLightCfg(color=(0.75, 0.75, 0.75), intensity=2500.0),
-    )
-
-
-##
-# MDP settings
-##
-
-
-@configclass
-class CommandsCfg:
-    """Command terms for the MDP."""
-
-    ee_pose = mdp.UniformPoseCommandCfg(
-        asset_name="robot",
-        body_name=MISSING,
-        resampling_time_range=(5.0, 5.0),
-        debug_vis=True,
-        ranges=mdp.UniformPoseCommandCfg.Ranges(
-            pos_x=(-0.1, 0.1),
-            pos_y=(-0.25, -0.1),
-            pos_z=(0.1, 0.3),
-            roll=(0.0, 0.0),
-            pitch=(0.0, 0.0),
-            yaw=(0.0, 0.0),
-        ),
-    )
-
-
-@configclass
-class ActionsCfg:
-    """Action specifications for the MDP."""
-
-    arm_action: ActionTerm = MISSING
-    gripper_action: ActionTerm | None = None
-
-
-@configclass
-class ObservationsCfg:
-    """Observation specifications for the MDP."""
-
-    @configclass
-    class PolicyCfg(ObsGroup):
-        """Observations for policy group."""
-
-        # observation terms (order preserved)
-        joint_pos = ObsTerm(func=mdp.joint_pos_rel, noise=Unoise(n_min=-0.01, n_max=0.01))
-        joint_vel = ObsTerm(func=mdp.joint_vel_rel, noise=Unoise(n_min=-0.01, n_max=0.01))
-        pose_command = ObsTerm(func=mdp.generated_commands, params={"command_name": "ee_pose"})
-        actions = ObsTerm(func=mdp.last_action)
-
-        def __post_init__(self):
-            self.enable_corruption = True
-            self.concatenate_terms = True
-
-    # observation groups
-    policy: PolicyCfg = PolicyCfg()
-
-
-@configclass
-class EventCfg:
-    """Configuration for events."""
-
-    reset_robot_joints = EventTerm(
-        func=mdp.reset_joints_by_scale,
-        mode="reset",
-        params={
-            "position_range": (0.5, 1.5),
-            "velocity_range": (0.0, 0.0),
-        },
-    )
-
-
-@configclass
-class RewardsCfg:
-    """Reward terms for the MDP."""
-
-    # task terms
-    end_effector_position_tracking = RewTerm(
-        func=mdp.position_command_error,
-        weight=-0.2,
-        params={"asset_cfg": SceneEntityCfg("robot", body_names=MISSING), "command_name": "ee_pose"},
-    )
-    end_effector_position_tracking_fine_grained = RewTerm(
-        func=mdp.position_command_error_tanh,
-        weight=0.1,
-        params={"asset_cfg": SceneEntityCfg("robot", body_names=MISSING), "std": 0.1, "command_name": "ee_pose"},
-    )
-    end_effector_orientation_tracking = RewTerm(
-        func=mdp.orientation_command_error,
-        weight=-0.1,
-        params={"asset_cfg": SceneEntityCfg("robot", body_names=MISSING), "command_name": "ee_pose"},
-    )
-
-    # action penalty
-    action_rate = RewTerm(func=mdp.action_rate_l2, weight=-0.0001)
-    joint_vel = RewTerm(
-        func=mdp.joint_vel_l2,
-        weight=-0.0001,
-        params={"asset_cfg": SceneEntityCfg("robot")},
-    )
-
-
-@configclass
-class TerminationsCfg:
-    """Termination terms for the MDP."""
-
-    time_out = DoneTerm(func=mdp.time_out, time_out=True)
-
-
-@configclass
-class CurriculumCfg:
-    """Curriculum terms for the MDP."""
-
-    action_rate = CurrTerm(
-        func=mdp.modify_reward_weight, params={"term_name": "action_rate", "weight": -0.005, "num_steps": 4500}
-    )
-
-    joint_vel = CurrTerm(
-        func=mdp.modify_reward_weight, params={"term_name": "joint_vel", "weight": -0.001, "num_steps": 4500}
-    )
-
-
-##
-# Environment configuration
-##
-
-
-@configclass
-class ReachEnvCfg(ManagerBasedRLEnvCfg):
-    """Configuration for the reach end-effector pose tracking environment."""
-
-    # Scene settings
-    scene: ReachSceneCfg = ReachSceneCfg(num_envs=4096, env_spacing=2.5)
-    # Basic settings
-    observations: ObservationsCfg = ObservationsCfg()
-    actions: ActionsCfg = ActionsCfg()
-    commands: CommandsCfg = CommandsCfg()
-    # MDP settings
-    rewards: RewardsCfg = RewardsCfg()
-    terminations: TerminationsCfg = TerminationsCfg()
-    events: EventCfg = EventCfg()
-    curriculum: CurriculumCfg = CurriculumCfg()
-
-    def __post_init__(self):
-        """Post initialization."""
-        # general settings
-        self.decimation = 2
-        self.sim.render_interval = self.decimation
-        self.episode_length_s = 12.0
-        self.viewer.eye = (2.5, 2.5, 1.5)
-        # simulation settings
-        self.sim.dt = 1.0 / 60.0
diff --git a/source/SO_100/SO_100/ui_extension_example.py b/source/SO_100/SO_100/ui_extension_example.py
deleted file mode 100644
index 48015d8..0000000
--- a/source/SO_100/SO_100/ui_extension_example.py
+++ /dev/null
@@ -1,51 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-import omni.ext
-
-
-# Functions and vars are available to other extension as usual in python: `example.python_ext.some_public_function(x)`
-def some_public_function(x: int):
-    print("[SO_100] some_public_function was called with x: ", x)
-    return x**x
-
-
-# Any class derived from `omni.ext.IExt` in top level module (defined in `python.modules` of `extension.toml`) will be
-# instantiated when extension gets enabled and `on_startup(ext_id)` will be called. Later when extension gets disabled
-# on_shutdown() is called.
-class ExampleExtension(omni.ext.IExt):
-    # ext_id is current extension id. It can be used with extension manager to query additional information, like where
-    # this extension is located on filesystem.
-    def on_startup(self, ext_id):
-        print("[SO_100] startup")
-
-        self._count = 0
-
-        self._window = omni.ui.Window("My Window", width=300, height=300)
-        with self._window.frame:
-            with omni.ui.VStack():
-                label = omni.ui.Label("")
-
-                def on_click():
-                    self._count += 1
-                    label.text = f"count: {self._count}"
-
-                def on_reset():
-                    self._count = 0
-                    label.text = "empty"
-
-                on_reset()
-
-                with omni.ui.HStack():
-                    omni.ui.Button("Add", clicked_fn=on_click)
-                    omni.ui.Button("Reset", clicked_fn=on_reset)
-
-    def on_shutdown(self):
-        print("[SO_100] shutdown")
diff --git a/source/SO_100/config/extension.toml b/source/SO_100/config/extension.toml
deleted file mode 100644
index 206f305..0000000
--- a/source/SO_100/config/extension.toml
+++ /dev/null
@@ -1,35 +0,0 @@
-[package]
-
-# Semantic Versioning is used: https://semver.org/
-version = "0.1.0"
-
-# Description
-category = "isaaclab"
-readme  = "README.md"
-
-title = "Extension Template"
-author = "Isaac Lab Project Developers"
-maintainer = "Isaac Lab Project Developers"
-description="Extension Template for Isaac Lab"
-repository = "https://github.com/isaac-sim/IsaacLab.git"
-keywords = ["extension", "template", "isaaclab"]
-
-[dependencies]
-"isaaclab" = {}
-"isaaclab_assets" = {}
-"isaaclab_mimic" = {}
-"isaaclab_rl" = {}
-"isaaclab_tasks" = {}
-# NOTE: Add additional dependencies here
-
-[[python.module]]
-name = "SO_100"
-
-[isaaclab_settings]
-# TODO: Uncomment and list any apt dependencies here.
-#       If none, leave it commented out.
-# apt_deps = ["example_package"]
-# TODO: Uncomment and provide path to a ros_ws
-#       with rosdeps to be installed. If none,
-#       leave it commented out.
-# ros_ws = "path/from/extension_root/to/ros_ws"
diff --git a/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_base.usd b/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_base.usd
deleted file mode 100644
index d410757..0000000
--- a/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_base.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:402eff31f89f535216709a98ae2464d016eb5d0791da26bd149413695f567f5f
-size 492
diff --git a/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_physics.usd b/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_physics.usd
deleted file mode 100644
index d410757..0000000
--- a/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_physics.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:402eff31f89f535216709a98ae2464d016eb5d0791da26bd149413695f567f5f
-size 492
diff --git a/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_sensor.usd b/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_sensor.usd
deleted file mode 100644
index d410757..0000000
--- a/source/SO_100/data/Robots/so_arm100/configuration/Livestream_test_sensor.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:402eff31f89f535216709a98ae2464d016eb5d0791da26bd149413695f567f5f
-size 492
diff --git a/source/SO_100/data/Robots/so_arm100/configuration/base_plate_layer1-v5.tmp.usd b/source/SO_100/data/Robots/so_arm100/configuration/base_plate_layer1-v5.tmp.usd
deleted file mode 100644
index c054b54..0000000
--- a/source/SO_100/data/Robots/so_arm100/configuration/base_plate_layer1-v5.tmp.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:14f5b1ce71e188136cee537e249c00e3d2fbd991d99953e1926883718b140c90
-size 421404
diff --git a/source/SO_100/data/Robots/so_arm100/so_100.usd b/source/SO_100/data/Robots/so_arm100/so_100.usd
deleted file mode 100644
index 2a727e9..0000000
--- a/source/SO_100/data/Robots/so_arm100/so_100.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:5296784b07bf131ba2e3763cd1e4e0eba7978d8b369d33330d6dc9b7e48bab06
-size 3910573
diff --git a/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_base.usd b/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_base.usd
deleted file mode 100644
index 8c96c33..0000000
--- a/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_base.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:479cad07b4cad80b684ee678b8a17d807ca3fa372f7ee8dd10368c16d6acc218
-size 4377627
diff --git a/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_physics.usd b/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_physics.usd
deleted file mode 100644
index 59b8d0e..0000000
--- a/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_physics.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:094acd14290308cd929deca3cf715fca8b650533eacf9501daec2c8f07a39de5
-size 4739
diff --git a/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_sensor.usd b/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_sensor.usd
deleted file mode 100644
index fd01aae..0000000
--- a/source/SO_100/data/Robots/so_arm100_roscon/configuration/so_arm100_sensor.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:14038447c801a8d8570571d3e82b20dd2e4dfcb21d713f0aa43cbabfd95fee5c
-size 649
diff --git a/source/SO_100/data/Robots/so_arm100_roscon/so_arm100.usd b/source/SO_100/data/Robots/so_arm100_roscon/so_arm100.usd
deleted file mode 100644
index 3f17d87..0000000
--- a/source/SO_100/data/Robots/so_arm100_roscon/so_arm100.usd
+++ /dev/null
@@ -1,3 +0,0 @@
-version https://git-lfs.github.com/spec/v1
-oid sha256:a8b7077a2e161ecd5829a7fa8d7c0e7d71b75d34220d6f6649d934475b05c769
-size 1596
diff --git a/source/SO_100/docs/CHANGELOG.rst b/source/SO_100/docs/CHANGELOG.rst
deleted file mode 100644
index cc48fe7..0000000
--- a/source/SO_100/docs/CHANGELOG.rst
+++ /dev/null
@@ -1,10 +0,0 @@
-Changelog
----------
-
-0.1.0 (2025-04-18)
-~~~~~~~~~~~~~~~~~~
-
-Added
-^^^^^
-
-* Created an initial template for building an extension or project based on Isaac Lab
diff --git a/source/SO_100/pyproject.toml b/source/SO_100/pyproject.toml
deleted file mode 100644
index d90ac35..0000000
--- a/source/SO_100/pyproject.toml
+++ /dev/null
@@ -1,3 +0,0 @@
-[build-system]
-requires = ["setuptools", "wheel", "toml"]
-build-backend = "setuptools.build_meta"
diff --git a/source/SO_100/setup.py b/source/SO_100/setup.py
deleted file mode 100644
index aae2984..0000000
--- a/source/SO_100/setup.py
+++ /dev/null
@@ -1,49 +0,0 @@
-# Copyright (c) 2024-2025, Muammer Bay (LycheeAI), Louis Le Lay
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-#
-# Copyright (c) 2022-2025, The Isaac Lab Project Developers.
-# All rights reserved.
-#
-# SPDX-License-Identifier: BSD-3-Clause
-
-"""Installation script for the 'SO_100' python package."""
-
-import os
-
-import toml
-from setuptools import setup
-
-# Obtain the extension data from the extension.toml file
-EXTENSION_PATH = os.path.dirname(os.path.realpath(__file__))
-# Read the extension.toml file
-EXTENSION_TOML_DATA = toml.load(os.path.join(EXTENSION_PATH, "config", "extension.toml"))
-
-# Minimum dependencies required prior to installation
-INSTALL_REQUIRES = [
-    # NOTE: Add dependencies
-    "psutil",
-]
-
-# Installation operation
-setup(
-    name="SO_100",
-    packages=["SO_100"],
-    author=EXTENSION_TOML_DATA["package"]["author"],
-    maintainer=EXTENSION_TOML_DATA["package"]["maintainer"],
-    url=EXTENSION_TOML_DATA["package"]["repository"],
-    version=EXTENSION_TOML_DATA["package"]["version"],
-    description=EXTENSION_TOML_DATA["package"]["description"],
-    keywords=EXTENSION_TOML_DATA["package"]["keywords"],
-    install_requires=INSTALL_REQUIRES,
-    license="MIT",
-    include_package_data=True,
-    python_requires=">=3.10",
-    classifiers=[
-        "Natural Language :: English",
-        "Programming Language :: Python :: 3.10",
-        "Isaac Sim :: 4.5.0",
-    ],
-    zip_safe=False,
-)